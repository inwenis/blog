{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Blog","text":""},{"location":"#my-blog-about-programming-other-stuff","title":"My blog about programming &amp; other stuff","text":"<p>If you find a typo or would like to improve my posts feel free to submit a pull request to https://github.com/inwenis/blog.</p> <p>Check out my other projects on my github like https://github.com/inwenis/collider where I tried to simulate Brownian motions.</p> <p>My collection of various kata's I've done: https://github.com/inwenis/kata</p> <p>I used to teach programming, out of sentiment I kept these two repos: - https://github.com/inwenis/sda.javawwa13.prog1.day5.complexity - https://github.com/inwenis/sda.javawwa13.prog1.day3.array_vs_hashtable</p> <p>Enjoy!</p> <p>You can reach me at <code>inwenis at gmail.com</code></p>"},{"location":"#me-gusta","title":"Me gusta","text":"<p>I don't have a better place for this yet so here's a list of links I like: - dict in F# - https://www.fssnip.net/fy/title/Typeinference-friendly-division-and-multiplication</p>"},{"location":"2021/06/12/f-async---be-mindful-of-what-you-put-in-async-/","title":"F# async - be mindful of what you put in async {}","text":"<pre><code>open System\n\nlet r = Random()\n\nlet m () =\n  let random_num = r.Next()\n  async {\n    printfn \"%i\" random_num\n  }\n\nm () |&gt; Async.RunSynchronously // prints a random number\nm () |&gt; Async.RunSynchronously // prints another random number\nlet x = m ()\nx |&gt; Async.RunSynchronously // prints another random number\nx |&gt; Async.RunSynchronously // prints same number as above\n</code></pre> <p>Why does it matter that lines 14 and 15 print the same number?</p> <p>Let's consider the following code:</p> <pre><code>// We're sending http requests and if they fail we'd like to retry them\n\n#r \"System.Net.Http\"\nopen System.Net.Http\n\nlet HTTP_CLIENT = new HttpClient()\n\nlet send url =\n  let httpRequest = new HttpRequestMessage()\n  httpRequest.RequestUri &lt;- Uri url\n\n  async {\n    let! r =\n      HTTP_CLIENT.SendAsync httpRequest\n      |&gt; Async.AwaitTask\n    return r\n  }\n\nsend \"http://test\" |&gt; Async.RunSynchronously\nsend \"http://test\" |&gt; Async.RunSynchronously\nlet y = send \"http://test\"\ny |&gt; Async.RunSynchronously\ny |&gt; Async.RunSynchronously\n\nlet retry computation =\n  async {\n    try\n      let! r = computation\n      return r\n    with\n    | e -&gt;\n      printf \"ups, err, let's retry\"\n      let! r2 = computation\n      return r2\n  }\n\nsend \"http://test\" |&gt; retry |&gt; Async.RunSynchronously\n// retrying will fail always with \"The request message was already sent. Cannot send the same request message multiple times.\"\n// This is because just like L14/15 print the same number, here we send the exact same request object and that's not allowed\n</code></pre> <p>The fix <pre><code>let send2 url =\n  async {\n    let httpRequest = new HttpRequestMessage()\n    httpRequest.RequestUri &lt;- Uri url\n    let! r =\n      HTTP_CLIENT.SendAsync httpRequest\n      |&gt; Async.AwaitTask\n    return r\n  }\n\nsend2 \"http://test\" |&gt; retry |&gt; Async.RunSynchronously\n</code></pre></p>"},{"location":"2022/10/28/exercises-in-bashshellscripting/","title":"Exercises in bash/shell/scripting","text":"<p>Being fluent in shell/scripting allows you to improve your work by 20%. It doesn't take you to another level. You don't suddenly poses the knowledge to implement flawless distributed transactions but some things get done much faster with no frustration.</p> <p>Here is my collection of shell/scripting exercises for others to practice shell skills.</p> <p>A side note - I'm still not sure if I should learn more PowerShell, try out a different shell or do everything in F# fsx. PowerShell is just so ugly ;(</p> <p>Scroll down for answers</p>"},{"location":"2022/10/28/exercises-in-bashshellscripting/#exercise-1","title":"Exercise 1","text":"<p>What were the arguments of <code>DetectOrientationScript</code> function in https://github.com/tesseract-ocr/tesseract when it was first introduced?</p>"},{"location":"2022/10/28/exercises-in-bashshellscripting/#exercise-2","title":"Exercise 2","text":"<p>Get <code>Hadoop distributed file system log</code> from https://github.com/logpai/loghub?tab=readme-ov-file</p> <p>Find the ratio of (failed block serving)/(failed block serving + successful block serving) for each IP</p> <p>The result should like: <pre><code>...\n10.251.43.210  0.452453987730061\n10.251.65.203  0.464609355865785\n10.251.65.237  0.455237129089526\n10.251.66.102  0.452124935995904\n...\n</code></pre></p>"},{"location":"2022/10/28/exercises-in-bashshellscripting/#exercise-3","title":"Exercise 3","text":"<p>This happened to me once - I had to find all http/s links to a specific domains in the export of our company's messages as someone shared proprietary code on websites available publicly.</p> <p>Exercise - find all distinct http/s links in https://github.com/tesseract-ocr/tesseract</p>"},{"location":"2022/10/28/exercises-in-bashshellscripting/#exercise-4","title":"Exercise 4","text":"<p>Task - remove the string \"42\" from each line of multiple CSV files.</p> <p>You can use this to generate the input CSV files: <pre><code>$numberOfFiles = 10\n$numberOfRows = 100\n\n$fileNames = 1..$numberOfFiles | % { \"file$_.csv\" }\n$csvData = 1..$numberOfRows | ForEach-Object {\n    [PSCustomObject]@{\n        Column1 = \"Value $_\"\n        Column2 = \"Value $($_ * 2)\"\n        Column3 = \"Value $($_ * 3)\"\n    }\n}\n\n$fileNames | % { $csvData | Export-Csv -Path $_ }\n</code></pre></p>"},{"location":"2022/10/28/exercises-in-bashshellscripting/#exercise-5","title":"Exercise 5","text":"<p>Just like me you created tens of repositories while writing code katas. Now you would like to keep all katas in a single repository. Write a script to move several repositories to a single repository. Each repo's content will end up in a dedicated directory in the new \"master\" repo. Remember to merge unrelated histories in the \"master\" repo.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p>"},{"location":"2022/10/28/exercises-in-bashshellscripting/#exercise-1-answer","title":"Exercise 1 - answer","text":"<p>Answer: <pre><code>bool DetectOrientationScript(int&amp; orient_deg, float&amp; orient_conf, std::string&amp; script, float&amp; script_conf);\n</code></pre></p> <pre><code>[PowerShell]\n&gt; git log -S DetectOrientationScript # get sha of oldest commit\n&gt; git show bc95798e011a39acf9778b95c8d8c5847774cc47 | sls DetectOrientationScript\n\n[bash]\n&gt; git log -S DetectOrientationScript # get sha of oldest commit\n&gt; git show bc95798e011a39acf9778b95c8d8c5847774cc47 | grep DetectOrientationScript\n</code></pre> <p>One-liner: <pre><code>[PowerShell]\n&gt; git log -S \" DetectOrientationScript\" -p | sls DetectOrientationScript | select -Last 1\n\n[bash]\n&gt; git log -S \" DetectOrientationScript\" -p | grep DetectOrientationScript | tail -1\n</code></pre></p>"},{"location":"2022/10/28/exercises-in-bashshellscripting/#bonus-execution-times","title":"Bonus - execution times","text":"<pre><code>[PowerShell 7.4]\n&gt; measure-command { git log -S \" DetectOrientationScript\" -p | sls DetectOrientationScript | select -Last 1 }\n...\nTotalSeconds      : 3.47\n...\n\n[bash]\n&gt; time git log -S \" DetectOrientationScript\" -p | grep DetectOrientationScript | tail -1\n...\nreal    0m3.471s\n...\n</code></pre> <p>Without <code>git log -S</code> doing heavy lifting times look different:</p> <p><pre><code>[PowerShell 7.4]\n&gt; @(1..10) | % { Measure-Command { git log -p | sls \"^\\+.*\\sDetectOrientationScript\" } } | % { $_.TotalSeconds } | Measure-Object -Average\n\nCount    : 10\nAverage  : 9.27122774\n</code></pre> <pre><code>[PowerShell 5.1]\n&gt; @(1..10) | % { Measure-Command { git log -p | sls \"^\\+.*\\sDetectOrientationScript\" } } | % { $_.TotalSeconds } | Measure-Object -Average\n\nCount    : 10\nAverage  : 27.33900077\n</code></pre> <pre><code>[bash]\n&gt; seq 10 | xargs -I '{}' bash -c \"TIMEFORMAT='%3E' ; time git log -p | grep -E '^\\+.*\\sDetectOrientationScript' &gt; /dev/null\" 2&gt; times\n&gt; awk '{s+=$1} END {print s}' times\n6.7249 # For convince I moved to dot one place to the left\n</code></pre></p>"},{"location":"2022/10/28/exercises-in-bashshellscripting/#reflections","title":"Reflections","text":"<p>Bash is faster then PowerShell. PowerShell 7 is much faster then PowerShell 5. It was surprisingly easy to get the average with <code>Measure-Object</code> in PowerShell and surprisingly difficult in bash.</p>"},{"location":"2022/10/28/exercises-in-bashshellscripting/#exercise-2-answer","title":"Exercise 2 - answer","text":"<pre><code>[PowerShell 7.4]\n&gt; sls \"Served block.*|Got exception while serving.*\" -Path .\\HDFS.log | % { $_.Matches[0].Value -replace \"Served block.*/\",\"ok/\" -replace \"Got exception while serving.*/\",\"nk/\" -replace \":\",\"\" } | % { $_ -replace \"(ok|nk)/(.*)\", \"`${2} `${1}\"} | sort &gt; sorted\n&gt; cat .\\sorted | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; ,@($_.name, ($g.Length/$_.count)) } | write-host\n</code></pre> <p>This is how I got to the answer: <pre><code>&gt; sls \"Served block\" -Path .\\HDFS.log | select -first 10\n&gt; sls \"Served block|Got exception while serving\" -Path .\\HDFS.log | select -first 10\n&gt; sls \"Served block|Got exception while serving\" -Path .\\HDFS.log | select -first 100\n&gt; sls \"Served block|Got exception while serving\" -Path .\\HDFS.log | select -first 1000\n&gt; sls \"Served block.*|Got exception while serving\" -Path .\\HDFS.log | select -first 1000\n&gt; sls \"Served block.*|Got exception while serving.*\" -Path .\\HDFS.log | select -first 1000\n&gt; sls \"Served block.*|Got exception while serving.*\" -Path .\\HDFS.log -raw | select -first 1000\n&gt; sls \"Served block.*|Got exception while serving.*\" -Path .\\HDFS.log -raw | select matches -first 1000\n&gt; sls \"Served block.*|Got exception while serving.*\" -Path .\\HDFS.log -raw | select Matches -first 1000\n&gt; sls \"Served block.*|Got exception while serving.*\" -Path .\\HDFS.log -raw | select Matches\n&gt; $a = sls \"Served block.*|Got exception while serving.*\" -Path .\\HDFS.log -raw\n&gt; $a[0]\n&gt; get-type $a[0]\n&gt; Get-TypeData $a\n&gt; $a[0]\n&gt; $a[0].Matches[0].Value\n&gt; $a = sls \"Served block.*|Got exception while serving.*\" -Path .\\HDFS.log\n&gt; $a[0]\n&gt; $a[0].Matches[0].Value\n&gt; sls \"Served block.*|Got exception while serving.*\" -Path .\\HDFS.log | % { $_.Matches[0].Value -replace \"Served block.*/\",\"ok/\" }\n&gt; \"asdf\" -replace \"a\",\"b\"\n&gt; \"asdf\" -replace \"a\",\"b\" -replace \"d\",\"x\"\n&gt; \"asdf\" -replace \"a.\",\"b\" -replace \"d\",\"x\"\n&gt; sls \"Served block.*|Got exception while serving.*\" -Path .\\HDFS.log | % { $_.Matches[0].Value -replace \"Served block.*/\",\"ok/\" -replace \"Got exception while serving.*/\",\"nk\" }\n&gt; sls \"Served block.*|Got exception while serving.*\" -Path .\\HDFS.log | % { $_.Matches[0].Value -replace \"Served block.*/\",\"ok/\" -replace \"Got exception while serving.*/\",\"nk/\" }\n&gt; sls \"Served block.*|Got exception while serving.*\" -Path .\\HDFS.log | % { $_.Matches[0].Value -replace \"Served block.*/\",\"ok/\" -replace \"Got exception while serving.*/\",\"nk/\" -replace \":\",\"\" }\n&gt; \"aaxxaa\" -replace \"a.\",\"b\"\n&gt; \"aaxxaa\" -replace \"a.\",\"b$0\"\n&gt; \"aaxxaa\" -replace \"a.\",\"b$1\"\n&gt; \"aaxxaa\" -replace \"a.\",\"b${1}\"\n&gt; \"aaxxaa\" -replace \"a.\",\"b${0}\"\n&gt; \"aaxxaa\" -replace \"a.\",\"b`${0}\"\n&gt; \"okaaxxokaa\" -replace \"(ok|no)aa\",\"_`{$1}_\"\n&gt; \"okaaxxokaa\" -replace \"(ok|no)aa\",\"_`${1}_\"\n&gt; \"okaaxxokaa\" -replace \"(ok|no)aa\",\"_`${1}_`${0}\"\n&gt; sls \"Served block.*|Got exception while serving.*\" -Path .\\HDFS.log | % { $_.Matches[0].Value -replace \"Served block.*/\",\"ok/\" -replace \"Got exception while serving.*/\",\"nk/\" -replace \":\",\"\" } | % { $_ -replace \"(ok|nk)/(.*)\", \"`${2} `${1}\"}\n&gt; sls \"Served block.*|Got exception while serving.*\" -Path .\\HDFS.log | % { $_.Matches[0].Value -replace \"Served block.*/\",\"ok/\" -replace \"Got exception while serving.*/\",\"nk/\" -replace \":\",\"\" } | % { $_ -replace \"(ok|nk)/(.*)\", \"`${2} `${1}\"} | sort\n&gt; sls \"Served block.*|Got exception while serving.*\" -Path .\\HDFS.log | % { $_.Matches[0].Value -replace \"Served block.*/\",\"ok/\" -replace \"Got exception while serving.*/\",\"nk/\" -replace \":\",\"\" } | % { $_ -replace \"(ok|nk)/(.*)\", \"`${2} `${1}\"} | sort &gt; sorted\n&gt; cat .\\sorted -First 10\n&gt; cat | group\n&gt; cat | group -Property {$_}\n&gt; cat .\\sorted | group -Property {$_}\n&gt; cat .\\sorted -Head 10 | group -Property {$_}\n&gt; cat .\\sorted -Head 100 | group -Property {$_}\n&gt; cat .\\sorted -Head 1000 | group -Property {$_}\n&gt; cat .\\sorted -Head 10000 | group -Property {$_}\n&gt; cat .\\sorted -Head 10000 | group -Property {$_} | select name,count\n&gt; cat .\\sorted | group -Property {$_} | select name,count\n&gt; cat .\\sorted | group -Property {$_ -replace \"nk|ok\",\"\"}\n&gt; cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"}\n&gt; cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; $_.name, $g.Length / $_.count }\n&gt; cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; $_.name, $g.Length, $_.count }\n&gt; cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; $_.name, $g.Length / $_.count }\n&gt; cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; $_.name, $g.Length, $_.count }\n&gt; $__\n&gt; $__[0]\n&gt; $__[1]\n&gt; $__[2]\n&gt; cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; $_.name, $g.Length, $_.count }\n&gt; $a = cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; $_.name, $g.Length, $_.count }\n&gt; $a[0]\n&gt; $a[1]\n&gt; $a[2]\n&gt; $a[1].GetType()\n&gt; $a[2].GetType()\n&gt; cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; $_.name, ($g.Length) / ($_.count) }\n&gt; cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; $_.name, (($g.Length) / ($_.count)) }\n&gt; cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; ,$_.name, (($g.Length) / ($_.count)) }\n&gt; cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; @($_.name, (($g.Length) / ($_.count))) }\n&gt; cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; ,@($_.name, (($g.Length) / ($_.count))) }\n&gt; cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; return ,@($_.name, (($g.Length) / ($_.count))) }\n&gt; cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; [Array] ,@($_.name, (($g.Length) / ($_.count))) }\n&gt; cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; [Array]@($_.name, (($g.Length) / ($_.count))) }\n&gt; cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; return ,$_.name, (($g.Length) / ($_.count)) }\n&gt; $a = cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; return ,$_.name, (($g.Length) / ($_.count)) }\n&gt; $a[0]\n&gt; $a = cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; return ,($_.name, (($g.Length) / ($_.count))) }\n&gt; cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; return ,($_.name, (($g.Length) / ($_.count))) }\n&gt; cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; return ,@($_.name, (($g.Length) / ($_.count))) }\n&gt; cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; ,@($_.name, (($g.Length) / ($_.count))) }\n&gt; cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; $x = @($_.name, (($g.Length) / ($_.count))) }\n&gt; cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; $x = @($_.name, (($g.Length) / ($_.count))); $x }\n&gt; cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; $x = @($_.name, (($g.Length) / ($_.count))); ,$x }\n&gt; cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; $x = @($_.name, (($g.Length) / ($_.count))); return ,$x }\n&gt; $a = cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; $x = @($_.name, (($g.Length) / ($_.count))); return ,$x }\n&gt; $a[0]\n&gt; $a[0][0]\n&gt; $a = cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; $x = @($_.name, (($g.Length) / ($_.count))); return ,$x } | % { wirte-output \"$_[0]\" }\n&gt; $a = cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; $x = @($_.name, (($g.Length) / ($_.count))); return ,$x } | % { write-output \"$_[0]\" }\n&gt; $a = cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; $x = @($_.name, (($g.Length) / ($_.count))); return ,$x } | % { write-output \"$_[0]\" }\n&gt; cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; $x = @($_.name, (($g.Length) / ($_.count))); return ,$x } | % { write-output \"$_[0]\" }\n&gt; cat .\\sorted -Head 10000 | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; $x = @($_.name, (($g.Length) / ($_.count))); return ,$x } | % { write-output \"$_\" }\n&gt; cat .\\sorted | group -Property {$_ -replace \"nk|ok\",\"\"} | % { $g = $_.group | ? {$_.contains(\"nk\") }; $x = @($_.name, (($g.Length) / ($_.count))); return ,$x } | % { write-output \"$_\" }\n</code></pre></p> <pre><code>[F#]\nopen System.IO\nopen System.Text.RegularExpressions\n\nlet lines = File.ReadAllLines(\"HDFS.log\")\n\nlet a =\n    lines\n    |&gt; Array.filter (fun x -&gt; x.Contains(\"Served block\") || x.Contains(\"Got exception while serving\"))\n\na\n// |&gt; Array.take 10000\n|&gt; Array.map (fun x -&gt;\n    let m = Regex.Match(x, \"(Served block|Got exception while serving).*/(\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})\")\n    m.Groups[2].Value,\n    match m.Groups[1].Value with\n    | \"Served block\"                -&gt; true\n    | \"Got exception while serving\" -&gt; false )\n|&gt; Array.groupBy fst\n|&gt; Array.map (fun (key, group) -&gt;\n    let total = group.Length\n    let failed = group |&gt; Array.map snd |&gt; Array.filter not |&gt; Array.length\n    key, (decimal failed)/(decimal total)\n    )\n|&gt; Array.sortBy fst\n|&gt; Array.map (fun (i,m) -&gt; sprintf \"%s  %.15f\" i m)\n|&gt; fun x -&gt; File.AppendAllLines(\"fsout\", x)\n</code></pre>"},{"location":"2022/10/28/exercises-in-bashshellscripting/#exercise-3-answer","title":"Exercise 3 - answer","text":"<pre><code>[PowerShell 7.4]\n&gt; ls -r -file | % { sls -path $_.FullName -pattern https?:.* -CaseSensitive } | % { $_.Matches[0].Value } | sort | select -Unique\n\n# finds 234 links\n</code></pre> <pre><code>[bash]\n&gt; find . -type f -not -path './.git/*' | xargs grep -E https?:.* -ho | sort | uniq\n\n# finds 234 links\n</code></pre>"},{"location":"2022/10/28/exercises-in-bashshellscripting/#exercise-4-answer","title":"Exercise 4 - answer","text":"<pre><code>[PowerShell 7.4]\nls *.csv | % { (cat $_ ) -replace \"42\",\"\" | out-file $_ }\n</code></pre> <p><pre><code>[bash]\n&gt; sed -i 's/43//' *.csv\n&gt; sed -ibackup 's/43//' *.csv # creates backup files\n</code></pre> This neat, perhaps unix people had wisdom that is lost now.</p>"},{"location":"2022/10/28/exercises-in-bashshellscripting/#exercise-5-answer","title":"Exercise 5 - answer","text":"<pre><code>$repos = @(\n    @(\"https://github.com/inwenis/kata.sortingitout\", \"sortingitout\", \"kata_sorting_it_out\"  ),\n    @(\"https://github.com/inwenis/anagrams_kata2\",    \"anagrams2\",    \"kata_anagrams2\"  ),\n    @(\"https://github.com/inwenis/anagram_kata\",      \"anagrams\",     \"kata\"  )\n)\n\n$repos | ForEach-Object {\n    $repo, $branch, $dir = $_\n    $repoName = $repo.Split(\"/\")[-1]\n    git clone $repo\n    pushd $repoName\n    git co -b $branch\n    $all = Get-ChildItem\n    mkdir $dir\n    $all | ForEach-Object {\n        Move-Item $_ -Destination $dir\n    }\n    git add -A\n    git cm -am \"move\"\n    git remote add kata https://github.com/inwenis/kata\n    git push -u kata $branch\n    popd\n    Remove-Item $repoName -Recurse -Force\n    Read-Host \"Press Enter to continue\"\n}\n</code></pre>"},{"location":"2023/05/09/short-post-on-premature-optimization-and-error-handling/","title":"Short post on premature optimization and error handling","text":"<p>Premature optimization is the root of all evil ~Donald Knuth</p> <p>Don't pretend to handle more than you handle ~me just now</p> <p>My team took over some scrapers. After a few months an issue is reported stating that accounting is missing data from one of the scrapers. No errors were logged and or seen by our team.</p> <p>My colleague investigates the issue. Findings:</p> <ul> <li>most recent data is indeed missing in our data base (it is already available in the API)</li> <li>the data is often delayed (compared to when it's available in the remote API)</li> <li>the data is not time critical but a delay of hours or days is vexing (remember folks - talk to your users or customers)</li> <li>the scraper is using parallelism to send all requests at once (probably to get the data faster)</li> <li>the API doesn't like our intense scraping and bans us from accessing the API, sometimes for hours</li> <li>we never saw any Errors as the error handling looks like this:</li> </ul> <pre><code>try {\n    data = hit the REST API using multiple parallel requests\n    persist(data)\n} catch {\n    log.info(\"No data found\")\n}\n</code></pre>"},{"location":"2023/05/09/short-post-on-premature-optimization-and-error-handling/#take-away","title":"Take away","text":"<ul> <li>talk to your users - in this case to learn that this data is not time critical</li> <li>don't optimize prematurely</li> <li>don't catch all exception pretending you handle them</li> </ul>"},{"location":"2023/05/09/short-post-on-premature-optimization-and-error-handling/#more-venting","title":"More venting","text":"<p>I have seen my share of premature optimizations. AFAIR I always managed to have a conversation about the (un)necessity of an optimization and agree to prefer readability/simplicity over premature optimization.</p> <p>If you see premature optimization my advise is \"talk to the perp\". People do what they consider necessary and right. They might optimize code hoping to save the company money or time.</p> <p>If you have the experience to know that saving 2kB of RAM in an invoicing app run once a month is not worth using that obscure data structure - talk to those who don't yet know it. Their intentions are good.</p> <p>I'm pretty sure I'm also guilty of premature optimization, just can't recall any instance as my brain is probably protecting my ego by erasing any memories of such mistakes from my past.</p>"},{"location":"2023/05/09/short-post-on-premature-optimization-and-error-handling/#an-example","title":"An example","text":"<p>One example of premature optimization stuck with me. I recall reviewing code as below</p> <pre><code>foreach(var gasPoint in gasPoints)\n{\n    if (gasPoint.Properties.Any())\n    {\n        foreach (var x in gasPoint.Properties)\n        {\n            // do sth with x\n        }\n    }\n}\n</code></pre> <p>The review went something like this:</p> <p>me: drop the if, foreach handles empty collections just fine</p> <p>author: but this is better</p> <p>me: why?</p> <p>author: if the collection is empty we don't even use the iterator</p> <p>me: how often is this code run?</p> <p>author: currently only for a single entry in gasPoints, but there can be more</p> <p>me: how many more and when?</p> <p>author: users might create an entry for every gas pipeline connection in Europe</p> <p>me: ok, how many is that?</p> <p>We agreed to drop the if after realizing that:</p> <p>We have ~30 countries in Europe, even if they all connect with each other there will be at most ~400 gas connections to handle here. We don't know that the if is faster then the iterator. 400 is extremely optimistic. We have 1 entry now, and realistically we will have 10 gasPoints in 5 years.</p> <p>The conversation wasn't as smooth as I pretend here but we managed.</p>"},{"location":"2023/05/09/short-post-on-premature-optimization-and-error-handling/#links","title":"Links","text":"<p>https://wiki.c2.com/?PrematureOptimization</p> <p>https://wiki.c2.com/?ProfileBeforeOptimizing</p> <p>https://youtube.com/CodeAesthetics/PrematureOptimization</p>"},{"location":"2024/06/17/it-will-be-great-set-it-up-dont-use-it-remove-it/","title":"It will be great, set it up, don't use it, remove it","text":"<p>Today, I removed something I allowed to be created despite initially feeling it was redundant.</p> <p>A year ago, a student found a tool to auto-generate documentation for our internal SDK from code annotations. They proposed embedding this documentation in our Continuous Integration pipeline. Although the idea sounded good on paper, I felt it wouldn\u2019t be used by our team. However, the team was enthusiastic.</p> <p>Everyone in our team has the SDK's git repo on their machine, and we rely on IntelliSense and the code for documentation. It seemed unlikely that we would change our habits since the new documentation wouldn\u2019t be easier to use than just using F12 to view the source code.</p> <p>Despite my doubts, I allowed this feature as the team lead. I had already rejected a few initiatives from that student and didn\u2019t want to kill their motivation. I wanted to let them work on something they found interesting. There was a slight chance I was wrong and the documentation might be used.</p> <p>Today, a year later, I noticed the docs website no longer works. It had been down for some time, and no one noticed because no one used it. I removed any trace of the published documentation.</p> <p>This made me reflect: was it wrong to allow something to be created that never paid off?</p> <p>In this case, the investment was small. The gain was that the student got to work on something interesting. So, I think it was right to let our team try it out and remove it once we were certain it wasn\u2019t used</p>"},{"location":"2024/05/06/axios-cookies--more/","title":"axios, cookies &amp; more","text":""},{"location":"2024/05/06/axios-cookies--more/#axios","title":"axios","text":"<p>axios - promise-based HTTP client for node.js</p> <ul> <li>when used in node.js axios uses http module (https://nodejs.org/api/http.html)</li> <li>in node axios does not support cookies by itself (https://github.com/axios/axios/issues/5742)<ul> <li>there are npm packages that add cookies support to axios</li> </ul> </li> <li>when used in browsers it uses XMLHttpRequest</li> <li>when used in browsers cookies work by default</li> </ul> <p>Why would you use <code>axios</code> over plain <code>http</code> module from node?</p> <p>Axios makes http requests much easier. Try using plain <code>http</code> and you'll convince your self.</p> <p>Are there other packages like <code>axios</code>?</p> <p>Yes - for example <code>node-fetch</code> https://github.com/node-fetch/node-fetch</p> <p>When making a request axios creates a default <code>http</code> and <code>https</code> agent - https://axios-http.com/docs/req_config (axios probably uses global agents). You can specify custom agents for a specific request or set custom agents as default agents to use with an <code>axios</code> instance.</p> <pre><code>const a = require('axios');\nconst http = require('node:http');\n\n(async () =&gt; {\n    // configure your agent as needed\n    const myCustomAgent = new http.Agent({ keepAlive: true });\n\n    // use your custom agent for a specific request\n    const x = await a.get('https://example.com/', { httpAgent: myCustomAgent });\n    console.log(x);\n\n    // set you agent as default for all requests\n    a.default.httpAgent = myCustomAgent;\n})();\n</code></pre> <p>What are <code>http</code>/<code>s</code> agents responsible for?</p> <p><code>http</code>/<code>s</code> agents handle creating/closing sockets, TCP, etc. They talk to the OS, manage connection to hosts.</p>"},{"location":"2024/05/06/axios-cookies--more/#cookies","title":"cookies","text":"<p>Without extra packages you need to code reading response headers, look for <code>Set-Cookie</code> headers. Store cookies somewhere. Code adding cookie headers to subsequent request.</p>"},{"location":"2024/05/06/axios-cookies--more/#http-cookie-agent","title":"<code>http-cookie-agent</code>","text":"<p>https://www.npmjs.com/package/http-cookie-agent</p> <p>Manages cookies for node.js HTTP clients (e.g. Node.js global fetch, undici, axios, node-fetch). <code>http-cookie-agent</code> implements a <code>http</code>/<code>s</code> agent that inspects request headers and does cookie related magic for you. It uses the class <code>CookieJar</code> from package <code>tough-cookie</code> to parse&amp;store cookies.</p> <pre><code>import axios from 'axios';\nimport { CookieJar } from 'tough-cookie';\nimport { HttpCookieAgent, HttpsCookieAgent } from 'http-cookie-agent/http';\n\nconst jar = new CookieJar();\n\nconst a = axios.create({\n  httpAgent: new HttpCookieAgent({ cookies: { jar } }),\n  httpsAgent: new HttpsCookieAgent({ cookies: { jar } }),\n});\n// now we have an axios instance supporting cookies\nawait a.get('https://example.com');\n</code></pre>"},{"location":"2024/05/06/axios-cookies--more/#axios-cookiejar-support","title":"<code>axios-cookiejar-support</code>","text":"<p>https://www.npmjs.com/package/axios-cookiejar-support</p> <p>Depends on <code>http-cookie-agent</code> and <code>tough-cookie</code>. Does the same as <code>http-cookie-agent</code> but you don't have to create <code>http</code>/<code>s</code> agents yourself. This is a small package that just intercepts axios requests and makes sure custom <code>http</code>/<code>s</code> agents are used source.</p> <p>Saves you a bit of typing but you can't use your own custom agents. If you need to configure your <code>http</code>/<code>s</code> agents (ex. with a certificate) - use <code>http-cookie-agent</code> (see github issue and github issue)</p> <pre><code>import axios from 'axios';\nimport { wrapper } from 'axios-cookiejar-support';\nimport { CookieJar } from 'tough-cookie';\n\nconst jar = new CookieJar();\nconst client = wrapper(axios.create({ jar }));\n\nawait client.get('https://example.com');\n</code></pre>"},{"location":"2024/05/06/axios-cookies--more/#tough-cookie","title":"<code>tough-cookie</code>","text":"<p>https://www.npmjs.com/package/tough-cookie</p> <p>npm package - cookie parsing/storage/retrieval (<code>tough-cookie</code> itself does nothing with http request).</p>"},{"location":"2024/05/06/axios-cookies--more/#a-bit-about-cookies","title":"A bit about cookies","text":"<p>https://datatracker.ietf.org/doc/html/rfc6265 - RFC describing cookies.</p> <p>https://datatracker.ietf.org/doc/html/rfc6265#page-28 - concise paragraph on Third-party cookies.</p> <p>Servers responds with a <code>Set-Cookie</code> header. Client can set the requested cookie. Cookies have a specific format described in this document.</p>"},{"location":"2024/05/06/axios-cookies--more/#random-stuff","title":"Random stuff","text":"<p>https://npmtrends.com/cookie-vs-cookiejar-vs-cookies-vs-tough-cookie</p> <p>interesting - <code>cookie</code> for servers are more popular than <code>tough-cookie</code> for clients since ~2023.</p> <p>Is this due to more serve side apps being written in node?</p>"},{"location":"2024/05/06/axios-cookies--more/#packages-we-dont-use","title":"Packages we don't use","text":"<ul> <li><code>cookie</code> - npm package - cookies for servers</li> <li><code>cookies</code> - npm package - cookies for servers (different then <code>cookie</code>)</li> <li><code>cookiejar</code> - npm package - a different cookie jar for clients</li> </ul>"},{"location":"2024/05/06/axios-cookies--more/#fetch-fetch-node-fetch","title":"fetch &amp; <code>fetch</code> &amp; <code>node-fetch</code>","text":"<p>fetch - standard created by WHATWG meant to replace <code>XMLHttpRequest</code> - https://fetch.spec.whatwg.org/</p> <p><code>fetch</code> - an old npm package to fetch web content - don't use it</p> <p><code>node-fetch</code> - community implemented <code>fetch</code> standard as a npm package - go ahead and use it</p> <p><code>fetch</code> - node's native implementation of the <code>fetch</code> standard - https://nodejs.org/dist/latest-v21.x/docs/api/globals.html#fetch</p> <p>Since <code>fetch</code> standard is the standard for both browsers and node chrome has a neat feature to export requests to <code>fetch</code></p>"},{"location":"2024/05/06/axios-cookies--more/#chat-gpt-crap","title":"chat-gpt crap","text":"<p>When researching I came across some chat-gpt generated content. You read it thinking it will be something but it's trash.</p> <p>https://www.dhiwise.com/post/managing-secure-cookies-via-axios-interceptors -&gt; this article from 2024 that tell you to implement cookies your self, doesn't even mention the word \"package\", \"module\"</p> <p>https://medium.com/@stheodorejohn/managing-cookies-with-axios-simplifying-cookie-based-authentication-911e53c23c8a -&gt; doesn't mention that cookies don't work in axios run in node without extra packages     (at least this one mentions that chat-gpt helped, thought I bet it's fully written by chat-gpt)</p> <p>inco note - our http client is misleading, it uses same agent for http and https, it should maybe be called customAgent</p>"},{"location":"2024/05/06/axios-cookies--more/#axios-and-fiddler","title":"axios and fiddler","text":"<p>Using a request interceptor (proxy) like fiddler helps during development and debugging.</p> <p>To make fiddler intercept axios request we have to tell axios that there is a proxy where all requests from should go. The proxy forwards those requests to the actual destination.</p> <pre><code>http_proxy=... // set proxy for http requests\nhttps_proxy=... // set proxy for https requests\nno_proxy=domain1.com,domain2.com // comma separated list of domains that should not be proxied\n</code></pre> <p>The proxy for both http and https can be the same url.</p> <p>Read more - https://axios-http.com/docs/req_config</p> <p>When using fiddler on windows I suggest going to <code>Network &amp; internet &gt; Proxy</code> and disableing proxies there (fiddler by default sets this). This way <code>fiddler</code> will only receive requests from the process where we set <code>http(s)_proxy</code> env vars.</p>"},{"location":"2024/05/06/axios-cookies--more/#fiddler-and-client-certificates","title":"fiddler and client certificates","text":"<p>I was not able to make fiddler work with client certificates. It should be done like this - https://docs.telerik.com/fiddler/configure-fiddler/tasks/respondwithclientcert but I couldn't get it to work</p>"},{"location":"2024/05/06/axios-cookies--more/#honorable-mentions","title":"honorable mentions","text":"<p>I would like to try out - https://www.npmjs.com/package/proxy-agent at some point</p> <p>I don't fully understand <code>withCredentials</code></p>"},{"location":"2024/05/06/axios-cookies--more/#axios-cookies-demo","title":"axios &amp; cookies demo","text":"<pre><code>&gt; npm i\n&gt; node server.mjs\nopen browser and go to http://127.0.0.1:3000\ncookies are supported\n&gt; node test.js (from another console)\ncookies are not supported\n</code></pre>"},{"location":"2024/05/06/axios-cookies--more/#axios-certificates-etc","title":"axios, certificates, etc","text":"<p>To use axios with a client certificate you need to configure the https agent with the key and cert. the key and cert need to be in pem format. They both can be in the same pem file, or in separate pem files. (did not try it) but you should be able to merge and split your pem.</p> <p>https://nodejs.org/api/tls.html#tlscreatesecurecontextoptions</p> <p>to try out - https://www.npmjs.com/package/proxy-agent</p>"},{"location":"2024/05/09/node-packages-updating/","title":"node packages updating","text":""},{"location":"2024/05/09/node-packages-updating/#tldr","title":"tl;dr","text":"<ol> <li><code>&gt; npm install depcheck -g</code> - install <code>depcheck</code> globally</li> <li><code>&gt; depcheck</code> - check for redundant packages</li> <li><code>&gt; npm un this-redundant-package</code> - uninstall redundant packages (repeat for all redundant packages)</li> <li>Create a pull-request <code>remove-redundant-packages</code></li> </ol> <ol> <li><code>&gt; npm i</code> - make order in <code>node_modules</code></li> <li><code>&gt; npm audit</code> - see vulnerability issues</li> <li><code>&gt; npm audit fix</code> - fix vulnerability issues that don't require attention</li> <li>Create a pull-request <code>fix-vulnerability-issues</code></li> </ol> <ol> <li><code>&gt; npm i npm-check-updates -g</code> - install <code>npm-check-updates</code> globally</li> <li><code>&gt; npm-check-updates</code> - see how outdated packages are</li> <li><code>&gt; npm outdated</code> - see how outdated packages are</li> <li><code>&gt; npm update --save</code> - update packages respecting your semver constraints from <code>packages.json</code></li> <li>If you have packages that use major version <code>0.*.*</code> you'll need to manually update these now<ul> <li><code>&gt; npm install that-one-package@latest</code></li> </ul> </li> <li>Create a pull-request <code>update-packages-minor</code></li> </ol> <p>If you're brave and can test/run you project easily:</p> <ol> <li><code>ncu -u</code> - updates <code>packages.json</code> to all latest versions as shown by <code>npm-check-updates</code><ul> <li>this might introduce breaking changes</li> </ul> </li> <li><code>npm i</code> - update <code>package-lock.json</code></li> <li>Test your project.</li> <li>Create a pull-request <code>update-packages-major</code></li> </ol> <p>If you're not brave or can't just YOLO and update all major versions:</p> <ol> <li><code>npm-check-updates</code> - check again what is left to update</li> <li><code>npm i that-package@latest</code> - update major version of of <code>that-package</code></li> <li>Test your project.<ul> <li>.js is dynamically typed so you might have just updated a package that breaks your project but you'll not know until you run your code</li> </ul> </li> <li>Repeat for all packages.</li> <li>Create a pull-request <code>update-packages-major</code></li> </ol>"},{"location":"2024/05/09/node-packages-updating/#longer-read","title":"longer read","text":"<p>Need to update dependencies in a node js project? Here are my notes on this.</p> <p><code>&gt; npm i</code> (<code>npm install</code>) <pre><code>&gt; npm i\n\nadded 60 packages, removed 124 packages, changed 191 packages, and audited 522 packages in 13s\n\n96 packages are looking for funding\n  run `npm fund` for details\n\n10 vulnerabilities (2 low, 7 moderate, 1 high)\n\nTo address issues that do not require attention, run:\n  npm audit fix\n\nTo address all issues possible (including breaking changes), run:\n  npm audit fix --force\n\nSome issues need review, and may require choosing\na different dependency.\n\nRun `npm audit` for details.\n</code></pre> - installs missing packages in <code>node_modules</code> - removes redundant packages in <code>node_modules</code> - installs correct versions of mismatched packages (if <code>packages-lock.json</code> wants a different version than found in <code>node_modules</code>) - shows what is going on with packaged in your project</p> <p><code>&gt; npm audit</code> - shows a report on vulnerability issues in your dependencies</p> <p><code>&gt; npm audit fix</code> - updates packages to address vulnerability issues (updates that do not require attention)</p> <p><code>&gt; npm outdated</code> - shows a table with your packages and versions <pre><code>$ npm outdated\nPackage      Current   Wanted   Latest  Location                  Depended by\nglob          5.0.15   5.0.15    6.0.1  node_modules/glob         dependent-package-name\nnothingness    0.0.3      git      git  node_modules/nothingness  dependent-package-name\nnpm            3.5.1    3.5.2    3.5.1  node_modules/npm          dependent-package-name\nlocal-dev      0.0.3   linked   linked  local-dev                 dependent-package-name\nonce           1.3.2    1.3.3    1.3.3  node_modules/once         dependent-package-name\n</code></pre></p> <ul> <li><code>Current</code> - what is in <code>nodes_modules</code></li> <li><code>Wanted</code> - most recent version that respect the version constraint from <code>packages.json</code></li> <li><code>Latest</code> - latest version from npm registry</li> </ul> <p>To update to latest minor+patch versions of your dependencies (<code>Wanted</code>) - <code>npm outdated</code> shows all you need to know but I prefer the output of <code>npm-check-updates</code></p> <p><code>&gt; npm i npm-check-updates -g</code> (<code>-g</code> -&gt; global mode - package will be available on your whole machine)</p> <p><code>&gt; npm-check-updates</code> - shows where an update will be a major/minor/patch update (I like the colors) <pre><code>Checking C:\\git\\blog\\package.json\n[====================] 39/39 100%\n\n @azure/storage-blob         ^12.5.0  \u2192      ^12.17.0\n adm-zip                     ^0.4.16  \u2192       ^0.5.12\n axios                       ^0.27.2  \u2192        ^1.6.8\n basic-ftp                    ^5.0.1  \u2192        ^5.0.5\n cheerio                 ^1.0.0-rc.6  \u2192  ^1.0.0-rc.12\n eslint                      ^8.12.0  \u2192        ^9.2.0\n eslint-config-prettier       ^8.5.0  \u2192        ^9.1.0\n eslint-plugin-import        ^2.25.4  \u2192       ^2.29.1\n fast-xml-parser              ^4.2.4  \u2192        ^4.3.6\n humanize-duration           ^3.27.3  \u2192       ^3.32.0\n iconv                        ^3.0.0  \u2192        ^3.0.1\n jsonwebtoken                 ^9.0.0  \u2192        ^9.0.2\n luxon                        ^3.4.3  \u2192        ^3.4.4\n</code></pre></p>"},{"location":"2024/05/09/node-packages-updating/#let-us-update-something","title":"Let us update something","text":"<p><code>&gt; npm update</code> - perform updates respecting your semver constraints and update <code>package-lock.json</code></p> <p><code>&gt; npm update --save</code> - same as above but also update <code>packages.json</code>, use this one always</p> <p>The behavior for packages with major version <code>0.*.*</code> is different than for versions &gt;=<code>1.0.0</code> (see <code>npm help update</code>)</p> <p><code>npm update</code> will most likely bump all minor and patch versions for you.</p> <p>You can run <code>npm update --save</code> often.</p>"},{"location":"2024/05/09/node-packages-updating/#what-do-the-symbols-in-packagejson-mean","title":"What do the symbols in <code>package.json</code> mean?","text":"<p>https://stackoverflow.com/questions/22343224/whats-the-difference-between-tilde-and-caret-in-package-json/25861938#25861938</p>"},{"location":"2024/05/09/node-packages-updating/#npm-update-save-vs-npm-audit-fix","title":"<code>npm update --save</code> vs <code>npm audit fix</code>","text":"<p><code>npm audit fix</code> will only update packages to fix vulnerability issues</p> <p><code>npm update --save</code> will update all packages it can (respecting semver constraints)</p>"},{"location":"2024/05/09/node-packages-updating/#do-i-have-unused-dependencies","title":"Do I have unused dependencies?","text":"<p><code>&gt; npm install depcheck -g</code></p> <p><code>&gt; depcheck</code> - shows unused dependencies. <code>depcheck</code> scans for <code>require</code>/<code>import</code> statements in your code so you might be utilizing a package differently but <code>depcheck</code> will consider it unused (ex. when you import packages using <code>importLazy</code>).</p>"},{"location":"2024/05/09/node-packages-updating/#npm-check","title":"npm-check","text":"<p><code>&gt; npm i npm-check -g</code></p> <p><code>&gt; npm-check</code> - a different tool to help with dependencies (I didn't use it)</p>"},{"location":"2024/05/09/node-packages-updating/#honorable-mentions","title":"honorable mentions","text":"<p><code>&gt; npm ls</code> - list installed packages (from <code>node_modules</code>)</p> <p><code>&gt; npm ls axios</code> - show all versions of axios and why we have them</p> <p><code>npm ls</code> will not show you origin of not-installed optional dependencies.</p> <p>Consider this - you devleop on a <code>win</code> maching and deploy your solution to a <code>linux</code> box. On windows (see below) you might think <code>node-gyp-build</code> is not used in your solution. <pre><code>&gt; npm ls node-gyp-build\ntest-npm@1.0.0 C:\\git\\test-npm\n`-- (empty)\n</code></pre></p> <p>But on a linux box it will be used: <pre><code>&gt; npm ls node-gyp-build\nnpm-test-proj@1.0.0 /git/npm-test-proj\n\u2514\u2500\u252c kafka-lz4-lite@1.0.5\n  \u2514\u2500\u252c piscina@3.2.0\n    \u2514\u2500\u252c nice-napi@1.0.2\n      \u2514\u2500\u2500 node-gyp-build@4.8.1\n</code></pre></p>"},{"location":"2024/05/18/notes-on-keys-certs-certificates-https-ssl-ssh-tls/","title":"Notes on keys, certs, certificates, HTTPS, SSL, SSH, TLS","text":"<p>key != cert (a key is different from a certificate)</p> <p>Keys are used to encrypt connections, certs are used to verify that the key owner is who he says he is.</p>"},{"location":"2024/05/18/notes-on-keys-certs-certificates-https-ssl-ssh-tls/#certificate-aka-cert","title":"Certificate aka cert","text":"<p>A certificate proves that a public key belongs to a given entity. The cert includes:</p> <ul> <li>public key</li> <li>information about the key</li> <li>CA's signature validating the cert</li> </ul> <p>CA's signature basically says \"I confirm that this public key belongs to this person/entity\". The signature is made using CA's private key.</p> <p>This is wikipedia certificate which I've exported from my chrome browser. This is the certificate in PEM format.</p> <pre><code>-----BEGIN CERTIFICATE-----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\nTJUd1W+d3LmikOUgGzil\n-----END CERTIFICATE-----\n</code></pre> <p>We can double click the cert file to view it (on Windows) or use many other different tools to view its content.</p> <p>https://stackoverflow.com/questions/9758238/how-to-view-the-contents-of-a-pem-certificate</p> <pre><code>&gt; $cert = New-Object Security.Cryptography.X509Certificates.X509Certificate2([string]\"C:\\Users\\inwen\\Downloads\\_.wikipedia.org.crt\")\n&gt; $cert | select *\n\nEnhancedKeyUsageList : {Server Authentication (1.3.6.1.5.5.7.3.1), Client Authentication (1.3.6.1.5.5.7.3.2)}\nDnsNameList          : {*.wikipedia.org, wikimedia.org, mediawiki.org, wikibooks.org...}\nSendAsTrustedIssuer  : False\nArchived             : False\nExtensions           : {System.Security.Cryptography.Oid, System.Security.Cryptography.Oid, System.Security.Cryptography.Oid, System.Security.Cryptography.Oid...}\nFriendlyName         :\nIssuerName           : System.Security.Cryptography.X509Certificates.X500DistinguishedName\nNotAfter             : 17/10/2024 01:59:59\nNotBefore            : 18/10/2023 02:00:00\nHasPrivateKey        : False\nPrivateKey           :\nPublicKey            : System.Security.Cryptography.X509Certificates.PublicKey\nRawData              : {48, 130, 8, 75...}\nSerialNumber         : 07419E39583A4C76CF1EA14347FA5F3A\nSubjectName          : System.Security.Cryptography.X509Certificates.X500DistinguishedName\nSignatureAlgorithm   : System.Security.Cryptography.Oid\nThumbprint           : 483F0C71F34AE0EA30D99BD60463DCDAA8F49DFB\nVersion              : 3\nHandle               : 2140299849504\nIssuer               : CN=DigiCert TLS Hybrid ECC SHA384 2020 CA1, O=DigiCert Inc, C=US\nSubject              : CN=*.wikipedia.org, O=\"Wikimedia Foundation, Inc.\", L=San Francisco, S=California, C=US\n</code></pre>"},{"location":"2024/05/18/notes-on-keys-certs-certificates-https-ssl-ssh-tls/#ssl-tls-ssh-sftp","title":"SSL &amp; TLS &amp; SSH &amp; SFTP","text":"<p>SSH (Secure SHell protocol) - protocol that allows to execute shell commands over a secure connection.</p> <p>SFTP is an extension of SSH. SFTP != FTP over SSH. To connect to a SFTP server you need a private ssh key. The public ssh key (your private key's counterpart) is stored at the server.</p> <p>TLS &amp; SSL - think of SSL as the older/first protocol for secure communication. SSL was outphased by TLS. TLS is THE protocol used by HTTPS for secure connections.</p> <p>Clients can be anonymous in TLS - usually the case on web - the server provides a cert to your browser but you don't need a cert of your own. TLS can be mutual - if the client has a cert the servers will/can validate it.</p>"},{"location":"2024/05/18/notes-on-keys-certs-certificates-https-ssl-ssh-tls/#putty","title":"PuTTy","text":"<p>PuTTy is free+open source software than can do SSH. PuTTy has its own format of key files -&gt; .ppk</p> <p>ppk - putty private key (ppk can be changed to pem with some software) A PPK file stores a private key, and the corresponding public key. Both are contained in the same file. https://tartarus.org/~simon/putty-snapshots/htmldoc/AppendixC.html</p>"},{"location":"2024/05/18/notes-on-keys-certs-certificates-https-ssl-ssh-tls/#pem","title":"PEM","text":"<p>Privacy-Enhanced Mail (PEM) is THE file format for exhanging keys, certificates.</p> <ul> <li><code>.cer</code> &amp; <code>.crt</code> - PEM file with a certificate</li> <li><code>.key</code> - PEM with with a private or public key</li> </ul> <p>The file extensions doesn't really matter. Just open the file and see the headers to be sure what it is.</p> <p>To view a pem certificate on Windows - rename it to <code>.crt</code> and double click.</p> <p>You can open a .pem file as plain text as see its content: <pre><code>// pem ignores stuff between the headers so you can put comments here\n\n-----BEGIN RSA PRIVATE KEY-----\nizfrNTmQLnfsLzi2Wb9xPz2Qj9fQYGgeug3N2MkDuVHwpPcgkhHkJgCQuuvT+qZI\nMbS2U6wTS24SZk5RunJIUkitRKeWWMS28SLGfkDs1bBYlSPa5smAd3/q1OePi4ae\ndU6YgWuDxzBAKEKVSUu6pA2HOdyQ9N4F1dI+F8w9J990zE93EgyNqZFBBa2L70h4\nM7DrB0gJBWMdUMoxGnun5glLiCMo2JrHZ9RkMiallS1sHMhELx2UAlP8I1+0Mav8\niMlHGyUW8EJy0paVf09MPpceEcVwDBeX0+G4UQlO551GTFtOSRjcD8U+GkCzka9W\n/SFQrSGe3Gh3SDaOw/4JEMAjWPDLiCglwh0rLIO4VwU6AxzTCuCw3d1ZxQsU6VFQ\nPqHA8haOUATZIrp3886PBThVqALBk9p1Nqn51bXLh13Zy9DZIVx4Z5Ioz/EGuzgR\nd68VW5wybLjYE2r6Q9nHpitSZ4ZderwjIZRes67HdxYFw8unm4Wo6kuGnb5jSSag\nvwBxKzAf3Omn+J6IthTJKuDd13rKZGMcRpQQ6VstwihYt1TahQ/qfJUWPjPcU5ML\n9LkgVwA8Ndi1wp1/sEPe+UlL16L6vO9jUHcueWN7+zSUOE/cDSJyMd9x/ZL8QASA\nETd5dujVIqlINL2vJKr1o4T+i0RsnpfFiqFmBKlFqww/SKzJeChdyEtpa/dJMrt2\n8S86b6zEmkser+SDYgGketS2DZ4hB+vh2ujSXmS8Gkwrn+BfHMzkbtio8lWbGw0l\neM1tfdFZ6wMTLkxRhBkBK4JiMiUMvpERyPib6a2L6iXTfH+3RUDS6A==\n-----END RSA PRIVATE KEY-----\n-----BEGIN CERTIFICATE-----\nMIICMzCCAZygAwIBAgIJALiPnVsvq8dsMA0GCSqGSIb3DQEBBQUAMFMxCzAJBgNV\nBAYTAlVTMQwwCgYDVQQIEwNmb28xDDAKBgNVBAcTA2ZvbzEMMAoGA1UEChMDZm9v\nMQwwCgYDVQQLEwNmb28xDDAKBgNVBAMTA2ZvbzAeFw0xMzAzMTkxNTQwMTlaFw0x\nODAzMTgxNTQwMTlaMFMxCzAJBgNVBAYTAlVTMQwwCgYDVQQIEwNmb28xDDAKBgNV\nBAcTA2ZvbzEMMAoGA1UEChMDZm9vMQwwCgYDVQQLEwNmb28xDDAKBgNVBAMTA2Zv\nbzCBnzANBgkqhkiG9w0BAQEFAAOBjQAwgYkCgYEAzdGfxi9CNbMf1UUcvDQh7MYB\nOveIHyc0E0KIbhjK5FkCBU4CiZrbfHagaW7ZEcN0tt3EvpbOMxxc/ZQU2WN/s/wP\nxph0pSfsfFsTKM4RhTWD2v4fgk+xZiKd1p0+L4hTtpwnEw0uXRVd0ki6muwV5y/P\n+5FHUeldq+pgTcgzuK8CAwEAAaMPMA0wCwYDVR0PBAQDAgLkMA0GCSqGSIb3DQEB\nBQUAA4GBAJiDAAtY0mQQeuxWdzLRzXmjvdSuL9GoyT3BF/jSnpxz5/58dba8pWen\nv3pj4P3w5DoOso0rzkZy2jEsEitlVM2mLSbQpMM+MUVQCQoiG6W9xuCFuxSrwPIS\npAqEAuV4DNoxQKKWmhVv+J0ptMWD25Pnpxeq5sXzghfJnslJlQND\n-----END CERTIFICATE-----\n</code></pre></p> <p>Contents between header and footer (<code>-----BEGIN CERTIFICATE-----</code> + <code>-----END CERTIFICATE-----</code>) is base64 encoded. The content can be DER binary data.</p>"},{"location":"2024/05/18/notes-on-keys-certs-certificates-https-ssl-ssh-tls/#der","title":"DER","text":"<p>Distinguished Encoding Rules - is a way of encoding data structures. A certificate is a data structure containing various entires like <code>validity date</code>, <code>issuer</code>, etc. For certificates to work you need to store this information and transfer it. DER encodes this information is a binary format. This is then after base64 encoded and then it goes into a PEM file.</p>"},{"location":"2024/05/18/notes-on-keys-certs-certificates-https-ssl-ssh-tls/#x509","title":"X.509","text":"<p>X.509 is the standard defining public key certificates for TLS/SSL (HTTPS)</p>"},{"location":"2024/05/18/notes-on-keys-certs-certificates-https-ssl-ssh-tls/#pfxp12pkcs12","title":"PFX/P12/PKCS12","text":"<p>PFX seems to be Microsoft's complicated file format for storing cryptographic data.</p> <p>P12/PKCS12 is the successor to PFX. Sometimes the terms PFX/P12/PKCS12 are used interchangeably.</p> <p>base64 offline decoder: https://www.glezen.org/Base64Decoder.html</p> <p>Nice description of certs vs key: https://superuser.com/questions/620121/what-is-the-difference-between-a-certificate-and-a-key-with-respect-to-ssl</p> <p>Generate yourself a certificate: https://getacert.com/index.html</p> <p>Important info on <code>rejectUnauthorized: false</code> and certificates in <code>axios</code>/<code>node</code>: https://stackoverflow.com/questions/51363855/how-to-configure-axios-to-use-ssl-certificate</p> <p>convention - propose     - specify format in secret name     - use plain - not base64 encoded</p>"},{"location":"2024/05/18/notes-on-keys-certs-certificates-https-ssl-ssh-tls/#converting","title":"Converting","text":"<pre><code># PFX/pkcs12 to PEM\nopenssl pkcs12 -in cert.pfx -out cert.pem -nodes\n\n# PFX/pkcs12 to PEM no password\nopenssl pkcs12 -in cert.p12 -out cert_without_pwd.pem -nodes -password pass:1234\n\n# PEM to PFX/pkcs12 (both have passwords)\nopenssl pkcs12 -export -out cert.pfx -in cert.pem -inkey cert.pem -passin pass:1234 -passout pass:1234\n\n# PEM to PFX/pkcs12 (when key and cert are in separate .pem files)\nopenssl pkcs12 -export -out bob_pfx.pfx -inkey bob_key.pem -in bob_cert.cert\n\n# if openssl hangs try running it using winpty\nwinpty openssl pkcs12 -in cert.pfx -out cert.pem -nodes\n</code></pre> <p>Sources:</p> <p>https://stackoverflow.com/questions/15413646/converting-pfx-to-pem-using-openssl</p> <p>https://stackoverflow.com/questions/808669/convert-a-cert-pem-certificate-to-a-pfx-certificate</p> <p>https://stackoverflow.com/questions/9450120/openssl-hangs-and-does-not-exit</p>"},{"location":"2024/05/18/notes-on-keys-certs-certificates-https-ssl-ssh-tls/#lazy-websites","title":"Lazy websites","text":"<p>Website's certificates are usually signed by intermediate CA, which in turn are signed by a trusted root CA. The idea is that the server you connect to send you its certificate with all the intermediate certificates. Your app/machine should have the root CA certificate stored so it can validate the chain of certificates it received from the server (by just validating the root cert sent with its own root CA).</p> <p>Some servers are misconfigured and do not send the intermediate certificates. You do not notice because browsers fill in the gaps for a better browsing experience. However when you try to scrape the same website with ex. node your connection will be rejected.</p>"},{"location":"2024/05/18/notes-on-keys-certs-certificates-https-ssl-ssh-tls/#donts-for-node","title":"don't's (for node)","text":"<p>Several answers on SO suggest:</p> <ul> <li><code>NODE_TLS_REJECT_UNAUTHORIZED=0</code> or </li> <li><code>const httpsAgent = new https.Agent({ rejectUnauthorized: false });</code></li> </ul> <p>Both are terrible ideas - they make your app accept unauthorized connections. They are the equivalent of this conversation:</p> <p>\"I can't verify this certificate, we can not be sure who we are connecting to\" - says Node with care in its voice</p> <p>\"Doesn't matter, YOLO, carry on\" - you reply shrugging your shoulders</p> <p>Read more here</p>"},{"location":"2024/05/18/notes-on-keys-certs-certificates-https-ssl-ssh-tls/#does-for-node","title":"does (for node)","text":"<p>Use NODE_EXTRA_CA_CERTS. Alternatively use a library to programmatically give node the missing certificate link</p> <p>Good read - https://stackoverflow.com/questions/31673587/error-unable-to-verify-the-first-certificate-in-nodejs</p>"},{"location":"2024/05/18/notes-on-keys-certs-certificates-https-ssl-ssh-tls/#root-ca-stores","title":"root CA stores","text":""},{"location":"2024/05/18/notes-on-keys-certs-certificates-https-ssl-ssh-tls/#node","title":"Node","text":"<p>It seems everyone has their own root CA store these days. Nodes has a hardcoded list of root CA see:</p> <ul> <li>https://github.com/nodejs/node/blob/main/src/node_root_certs.h</li> <li>https://github.com/nodejs/node/issues/4175</li> </ul>"},{"location":"2024/05/18/notes-on-keys-certs-certificates-https-ssl-ssh-tls/#windows","title":"Windows","text":"<p>You can view Windows certificates with PowerShell: <pre><code>Get-ChildItem -Recurse Cert:\n</code></pre></p>"},{"location":"2024/05/18/notes-on-keys-certs-certificates-https-ssl-ssh-tls/#chrome","title":"Chrome","text":"<p>https://chromium.googlesource.com/chromium/src/+/main/net/data/ssl/chrome_root_store/root_store.md</p> <p>If you would like to become chrome's trusted CA - https://www.chromium.org/Home/chromium-security/root-ca-policy/</p> <p>https://blog.chromium.org/2022/09/announcing-launch-of-chrome-root-program.html</p>"},{"location":"2024/07/14/how-the-way-i-workcodeinvestigatedebug-changed-with-time--experience/","title":"How the way I work/code/investigate/debug changed with time &amp; experience","text":"<p>I use this metaphor when describing how I work these days.</p>"},{"location":"2024/07/14/how-the-way-i-workcodeinvestigatedebug-changed-with-time--experience/#tldr","title":"TL;DR;","text":"<ol> <li>Quick feedback is king<ul> <li>unit tests</li> <li>quick test in another way</li> <li>reproduce issues locally</li> <li>try things out in a small project on the side, not in the project you're working on</li> </ul> </li> <li>One thing at a time<ul> <li>experimenting</li> <li>refactoring preparing for feature addition</li> <li>feature coding</li> <li>cleaning up after feature coding</li> </ul> </li> <li>Divide problems into smaller problems<ul> <li>and remember - one thing (problem) at a time</li> </ul> </li> </ol>"},{"location":"2024/07/14/how-the-way-i-workcodeinvestigatedebug-changed-with-time--experience/#example","title":"Example","text":"<p>You're working with code that talks to a remote API, you want to test different API calls to the remote API.</p> <p>don't - change API parameters in code and run the project each time you test something. It takes too long.</p> <p>do - write a piece of code to send an HTTP request, fiddle with this code</p> <p>do - intercept request with <code>Fiddler</code>/<code>Postman</code>/other interceptor and reissue requests with different parameters</p>"},{"location":"2024/07/14/how-the-way-i-workcodeinvestigatedebug-changed-with-time--experience/#example_1","title":"Example","text":"<p>Something fails in the CI pipeline.</p> <p>don't - make a change, commit, wait for remote CI to trigger, see result</p> <p>do - reproduce issue locally</p>"},{"location":"2024/07/14/how-the-way-i-workcodeinvestigatedebug-changed-with-time--experience/#longer-read","title":"Longer read","text":"<ol> <li>Quick feedback</li> <li>do - write a test for it</li> <li>do - isolate your issue/suspect/the piece of code you're working with<ul> <li>it is helpful if you can run just a module/sub-system/piece of your project/system</li> <li>partial execution helps - like in Python/Jupyter or F# fsx</li> </ul> </li> <li>if you rely on external data and it takes time to retrieve it (even a 5-second delay can be annoying) - dump data to a file and read it from the file instead of hitting an external API or a DB every time you run your code</li> <li>don't try to understand how <code>List.foldBack()</code> works while debugging a big project. Do it on the side.</li> <li>spin up a new solution/project on the side to test things</li> <li> <p>occasional juniors ask \"does this work this way\" - you can test it yourself easily if you do it on the side</p> </li> <li> <p>One thing at a time</p> </li> <li>separate refactoring from feature addition</li> <li>fiddle first, find the walls/obstacles</li> <li><code>git reset --hard</code></li> <li>refactor preparing for a new feature (can become a separate PR)</li> <li>code feature</li> <li>if during coding you find something that needs refactoring/renaming/cleaning up - any kind of \"WTF is this? I need to fix this!\" try a) or b)<ul> <li>a) make a note to fix it later</li> <li>b) fix immediately     <pre><code>&gt; git stash\n&gt; git checkout master\n&gt; git checkout -b fix-typo\nfix stuff\nmerge or create a PR\ngit checkout feature\n&gt; git merge fix-typo or git rebase fix-typo\ncontinue work\n</code></pre></li> </ul> </li> <li> <p>always have a paper notepad on your desk</p> <ul> <li>note things you would like to come back to or investigate</li> <li>it gives me great satisfaction to go through a list of \"side quests\" I have noted and strike through all of them, knowing I have dealt with each one before starting a new task</li> <li>when investigating something I also note questions I would like to be able to answer after I'm done investigating<ul> <li>example: while working with Axios and cookies I found conflicting information about whether Axios supports cookies. After the investigation, I knew that Axios supports cookies by default in a browser but not in Node.js</li> </ul> </li> </ul> </li> <li> <p>Divide problems into smaller problems</p> </li> <li>example - coding logic for a new feature in a CLI tool and designing the CLI arguments - these can be 2 sub-tasks</li> </ol>"},{"location":"2024/07/14/how-the-way-i-workcodeinvestigatedebug-changed-with-time--experience/#big-bang-vs-baby-steps","title":"Big bang vs baby steps","text":"<p>The old me often ended up doing the big bang. Rewriting large chunks of code at once. Starting things from scratch. Working for hours or days with a codebase that can't even compile.</p> <p>Downsides    - for a long time the project doesn't even compile, I lose motivation, I feel like I'm walking in the dark, I don't see errors for a long time    - requires a lot of context keeping in my mind since I've ripped the project apart    - if I abandon work for a few days sometimes I forget everything and progress is lost</p> <p>The new me prefers baby steps</p> <p>Fiddle with the code knowing I'll <code>git reset --hard</code>. Try renaming some stuff - helps me understand the codebase better. Try out different things and abandon them. At this point, I usually get an idea/feeling of what needs to be done. Plan a few smaller refactorings. After them, I am usually closer to the solution and am able to code it without a big bang.</p>"},{"location":"2024/06/24/powershell-quirk/","title":"PowerShell quirk","text":""},{"location":"2024/06/24/powershell-quirk/#tldr","title":"tl;dr","text":"<p>In PowerShell if you want to return an array instead of one element of the array at the time do this: <pre><code>&gt; @(1..2) | % { $a = \"a\" * $_; @($a,$_) } # wrong! will pipe/return 1 element at a time\n&gt; @(1..2) | % { $a = \"a\" * $_; ,@($a,$_) } # correct! will pipe/return pairs\n</code></pre> Beware! Result of both snippets will be displayed in the exact same way even though they have different types! See below: <pre><code>&gt; @(1,2,3,4)\n1\n2\n3\n4\n&gt; @((1,2),(3,4))\n1\n2\n3\n4\n</code></pre></p> <p>To check actual types: <pre><code>&gt; $x = @(1..2) | % { $a = \"a\" * $_; @($a,$_) } ; $x.GetType().Name ; $x[0].GetType().Name ; $x\n&gt; $x = @(1..2) | % { $a = \"a\" * $_; ,@($a,$_) } ; $x.GetType().Name ; $x[0].GetType().Name ; $x\n# Alternatively\n&gt; @(1..2) | % { $a = \"a\" * $_; @($a,$_) } | Get-Member -name GetType\n&gt; @(1..2) | % { $a = \"a\" * $_; ,@($a,$_) } | Get-Member -name GetType\n# Get-Member only shows output for every distinct type\n</code></pre></p>"},{"location":"2024/06/24/powershell-quirk/#longer-read","title":"Longer read","text":"<p>Occasionally I have a fist fight with PS to return an Array instead of one element at a time. PS is a tough oponent. I think I get it now though.</p> <p>The comma <code>,</code> in PS is a binary and unary operator. You can use it with a single or 2 arguments. <pre><code>&gt; ,1 # as an unary operator the comma creates an array with 1 member\n1\n&gt; 1,2 # as an binary operator the comma creates an array with 2 members\n1\n2\n</code></pre></p> <p>Beware that both an array[] and array[][] will be displayed the same way. <code>$y</code> is an array[][], it is printed the same way to the output as <code>$x</code> <pre><code>&gt; $x = @(1,2,3,4) ; $x.GetType().Name ; $x[0].GetType().Name ; $x\nObject[]\nInt32\n1\n2\n3\n4\n&gt; $y = @((1,2),(3,4)) ; $y.GetType().Name ; $y[0].GetType().Name ; $y\nObject[]\nObject[]\n1\n2\n3\n4\n</code></pre></p> <p>If you're trying to return an array of pairs: <pre><code>&gt; @(1..2) | % { $a = \"a\" * $_; @($a,$_) } # wrong\na\n1\naa\n2\n&gt; @(1..2) | % { $a = \"a\" * $_; ,@($a,$_) } # correct!\na\n1\naa\n2\n# Even though the result looks like a flat array this this time it's an array of arrays\n&gt; @(1..2) | % { $a = \"a\" * $_; @($a,$_) } | Get-Member -name GetType # we get strings and ints\n\n   TypeName: System.String\n\nName    MemberType Definition\n----    ---------- ----------\nGetType Method     type GetType()\n\n   TypeName: System.Int32\n\nName    MemberType Definition\n----    ---------- ----------\nGetType Method     type GetType()\n\n&gt; @(1..2) | % { $a = \"a\" * $_; ,@($a,$_) } | Get-Member -name GetType # we get arrays\n\n   TypeName: System.Object[]\n\nName    MemberType Definition\n----    ---------- ----------\nGetType Method     type GetType()\n</code></pre></p> <p>More on printing your arrays of pairs: <pre><code>&gt; @(1..4) | % { $a = \"a\" * $_; ,@($a,$_) } | write-output # write-output will \"unwind\" your array\na\n1\naa\n2\n&gt; @(1..4) | % { $a = \"a\" * $_; ,@($a,$_) } | write-host\na 1\naa 2\n&gt; @(1..4) | % { $a = \"a\" * $_; ,@($a,$_) } | % { write-output \"$_\" }\na 1\naa 2\n&gt; @(1..4) | % { $a = \"a\" * $_; ,@($a,$_) } | write-output -NoEnumerate # returns an array of arrays but it's printed as if it's a flat array\na\n1\naa\n2\n</code></pre></p> <p>This https://stackoverflow.com/a/29985418/2377787 explains how <code>@()</code> works in PS.</p> <p><pre><code>&gt; $a='A','B','C'\n&gt; $b=@($a;)\n&gt; $a\nA\nB\nC\n&gt; $b\nA\nB\nC\n&gt; [Object]::ReferenceEquals($a, $b)\nFalse\n</code></pre> Above <code>$a;</code> is understood as <code>$a</code> is a collection, collections should be enumerated and each item is passed to the pipeline. <code>@($a;)</code> sees 3 elements but not the original array and creates an array from the 3 elements. In PS <code>@($collection)</code> creates a copy of <code>$collection</code>. <code>@(,$collection)</code> - creates an array with a single element <code>$collection</code>.</p>"},{"location":"2024/06/30/my-recommendations/","title":"My recommendations","text":""},{"location":"2024/06/30/my-recommendations/#terminal-etc","title":"Terminal etc.","text":"<ul> <li>https://github.com/PowerShell/PowerShell - PowerShell 7+ - faster &amp; better then Windows PowerShell</li> <li>https://ohmyposh.dev/ - amazing prompts - replace that old <code>$</code> sign with amazing stuff</li> <li>https://github.com/dahlbyk/posh-git - offers a prompt for git repos. Comes bundled with <code>oh-my-posh</code> for PowerShell. Use <code>oh-my-posh</code> prompt and <code>posh-git</code> for autocompletion.</li> </ul>"},{"location":"2024/06/30/my-recommendations/#git","title":"git","text":"<ul> <li>https://www.toptal.com/developers/gitignore - .gitignore files for your project</li> <li>https://rtyley.github.io/bfg-repo-cleaner/ - remove password from git history &amp; more</li> </ul>"},{"location":"2024/06/30/my-recommendations/#node","title":"node","text":"<ul> <li>https://github.com/nvm-sh/nvm - node version manager - install several versions of node and switch between them</li> <li>https://github.com/coreybutler/nvm-windows - same as ^ but for windows</li> </ul>"},{"location":"2024/06/30/my-recommendations/#http","title":"http","text":"<ul> <li>https://www.telerik.com/fiddler/fiddler-classic - inspect http traffic/modify &amp; replay requests</li> </ul>"},{"location":"2024/06/30/my-recommendations/#other","title":"other","text":"<ul> <li>https://nomacs.org/ - free, open source image viewer - because the default Windows one sux</li> <li>https://keepass.info/ - free safe password database</li> <li>https://www.videolan.org/vlc/ - my go to video player</li> </ul>"},{"location":"2024/07/15/powershell-oopsie/","title":"PowerShell \"Oopsie\"","text":""},{"location":"2024/07/15/powershell-oopsie/#task-remove-a-specific-string-from-each-line-of-multiple-csv-files","title":"Task - remove a specific string from each line of multiple CSV files.","text":"<p>This task was added to the scripting exercise list.</p> <p>First - let's generate some CSV files to work with: <pre><code>$numberOfFiles = 10\n$numberOfRows = 100\n\n$fileNames = 1..$numberOfFiles | % { \"file$_.csv\" }\n$csvData = 1..$numberOfRows | ForEach-Object {\n    [PSCustomObject]@{\n        Column1 = \"Value $_\"\n        Column2 = \"Value $($_ * 2)\"\n        Column3 = \"Value $($_ * 3)\"\n    }\n}\n\n$fileNames | % { $csvData | Export-Csv -Path $_ }\n</code></pre></p>"},{"location":"2024/07/15/powershell-oopsie/#the-oopsie","title":"The \"Oopsie\"","text":"<pre><code>ls *.csv | % { cat $_ | % { $_ -replace \"42\",\"\" } | out-file $_ -Append }\n</code></pre> <p>This command will never finish. Run it for a moment (and then kill it), see the result, and try to figure out what happens. Explanation below.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p> <p>.</p>"},{"location":"2024/07/15/powershell-oopsie/#the-explanation","title":"The explanation","text":"<p><code>Get-Content</code> (aka. <code>cat</code>) keeps the file open and reads the content that our command is appending, thus creating an infinite loop.</p>"},{"location":"2024/07/15/powershell-oopsie/#the-fix","title":"The fix","text":"<p>There are many ways to fix this this \"oopsie\"</p> <p>Perhaps the simplest one is to not write to and read from the exact same file. A sensible rule is when processing files always write to a different file:</p> <pre><code>ls *.csv | % { cat $_ | % { $_ -replace \"42\",\"\" } | out-file -path \"fixed$($_.Name)\" }\n</code></pre> <p>Knowing the reason for our command hanging we can make sure the whole file is read before we overwrite it: <pre><code>ls *.csv | % { (cat $_ ) | % { $_ -replace \"42\",\"\" } | out-file $_ }\nls *.csv | % { (cat $_ ) -replace \"42\",\"\" | out-file $_ } # we can also use -replace as an array operator\n</code></pre></p> <p>I'm amazed by github's co-pilot answer for \"powershell one liner to remove a specific text from multiple CSV files\":</p> <pre><code>Get-ChildItem -Filter \"*.csv\" | ForEach-Object { (Get-Content $_.FullName) -replace \"string_to_replace\", \"replacement_string\" | Set-Content $_.FullName }\n</code></pre>"},{"location":"2024/12/13/3-regex/","title":"&lt;3 regex","text":"<p>https://regex101.com/r/RdCR7j/1 - set the global flag (g) to get all matches</p> <p>https://www.debuggex.com/ - havent't played with this a lot but I might give it a try, looks like a decent learning tool</p>"},{"location":"2024/12/13/3-regex/#regex-use-static-regexmatches-or-instantiante-regex","title":"regex - use static Regex.Matches() or instantiante Regex()?","text":"<p>By default use static method.</p> <p>.NET regex engine caches regexes (by default 15).</p> <p>Are you using more than 15 regexes and use them frequently and they're complex and you care about a performance?</p> <p>Investigate <code>Regex()</code> and <code>RegexOptions.Compiled</code> <code>RegexOptions.CompiledToAssembly</code></p> <p>Test performance before you optimize</p> <p>https://learn.microsoft.com/en-us/dotnet/standard/base-types/best-practices-regex#static-regular-expressions</p> <p>https://learn.microsoft.com/en-us/dotnet/api/system.text.regularexpressions.regexoptions?view=net-9.0</p>"},{"location":"2024/12/13/3-regex/#what-is-the-whole-fus-about-backtracing","title":"What is the whole fus about backtracing?","text":"<p>Microsoft's documentation does a bad job explaning backtracking.</p> <p>Read about backtracking here - https://www.regular-expressions.info/catastrophic.html</p> <p>To experience backtracing yourself - https://regex101.com/r/1rWKNN/1 - keep on adding \"x\" to the input and see how the execution time increses - with 35*\"x\" it takes 5 seconds for the regex to find out it doesn't match!</p>"},{"location":"2024/12/13/3-regex/#code","title":"Code","text":"<p>These are the methods you need:</p> <p><pre><code>open System\nopen System.Text.RegularExpressions\n\n\nRegex.Matches(\"input\", \"pattern\")\nRegex.Matches(\"input\", \"pattern\", RegexOptions.IgnoreCase ||| RegexOptions.Singleline)\nRegex.Matches(\"input\", \"pattern\", RegexOptions.IgnoreCase ||| RegexOptions.Singleline, TimeSpan.FromSeconds(10.)) // you can use a timeout to prevent a DoS attack with malicous inputs\nRegex.Match()\nRegex.IsMatch()\nRegex.Replace()\nRegex.Split()\nRegex.Count()\n\nlet r = new Regex(\"pattern\") // instance Regex offers the same methods\nr.Matches(\"input\")\n</code></pre> Regex class - https://learn.microsoft.com/en-us/dotnet/api/system.text.regularexpressions.regex?view=net-9.0</p> <p>Sample:</p> <p><pre><code>let matches = Regex.Matches(\"Lorem ipsum dolor sit amet, consectetur adipiscing elit\", \"(\\w)o\")\nmatches |&gt; Seq.iter (fun x -&gt; printfn \"%s\" x.Value)\nmatches |&gt; Seq.iter (fun x -&gt; printfn \"%A\" x.Groups)\nmatches.[0].Groups.[1].Value |&gt; printfn \"%s\"\n\n// Lo             // these are the whole matches\n// do             //\n// lo             //\n// co             //\n// seq [Lo; L]    // group 0 is the whole match, group 1 is the (\\w)\n// seq [do; d]    //\n// seq [lo; l]    //\n// seq [co; c]    //\n// L              // this is the letter captured by (\\w)\n\nlet matches2 = Regex.Matches(\"Lorem ipsum dolor sit amet, consectetur adipiscing elit\", \"(\\w)+o\")\nmatches2.[1].Groups.[1].Value |&gt; printfn \"%A\"\nmatches2.[1].Groups.[1].Captures |&gt; Seq.iter (fun c -&gt; printfn \"%s\" c.Value)\n// l              // gotcha! the value of the group is the last thing captured by that group\n// d              // here the (\\w)+ group captures 3 times\n// o              //\n// l              //\n</code></pre> <pre><code>Match object properties:\nMatch.Success -&gt; bool   | true      | false        |\nMatch.Value   -&gt; string | the match | String.Empty |\n</code></pre> <pre><code>let match3 = Regex.Match(\"Lorem ipsum dolor sit amet, consectetur adipiscing elit\", \"Lorem i[a-z ]+i\")\nmatch3.Success |&gt; printfn \"%A\"\nmatch3.Value   |&gt; printfn \"%A\"\n// true\n// \"Lorem ipsum dolor si\"\n\nlet match4 = Regex.Match(\"Lorem ipsum dolor sit amet, consectetur adipiscing elit\", \"Lorem i[A-Z ]+i\")\nmatch4.Success            |&gt; printfn \"%A\"\nmatch4.Value              |&gt; printfn \"%A\"\nmatch4.Groups.Count       |&gt; printfn \"%A\"\nmatch4.Groups.[0].Success |&gt; printfn \"%A\"\n// false\n// \"\"    // notice this is String.empty not &lt;null&gt;\n// 1     // even for a failed match there is always at least one group\n// false\n</code></pre></p> <pre><code>let mutable m = Regex.Match(\"Lorem ipsum dolor sit amet, consectetur adipiscing elit\", \"\\wo\")\nwhile m.Success do\n    printfn \"%s\" m.Value\n    m &lt;- m.NextMatch()\n\nlet lines = [\n    \"The next day the children were ready to go to the plum thicket in the\"\n    \"peach orchard as soon as they had their breakfast, but while they were\"\n    \"talking about it a new trouble arose. It grew out of a question asked by\"\n    \"Drusilla.\"\n]\n\nlines\n|&gt; List.filter (fun line -&gt; Regex.IsMatch(line, \"the\"))\n|&gt; List.map    (fun line -&gt; Regex.Replace(line, \"(\\w+) the\", \"the $1\"))\n\nlet text =\n    \"don't we all love\\n\" +\n    \"dealing with different\\r\\n\" +\n    \"line endings\\n\" +\n    \"it's so much fun\"\nRegex.Split(text, \"\\r?\\n\")\n|&gt; Array.iter (printfn \"%s\")\n\nopen System.Net.Http\nlet book = (new HttpClient()).GetStringAsync(\"https://www.gutenberg.org/cache/epub/74886/pg74886.txt\").Result\nRegex.Count(book, \"[^\\w]\\w{3}[^\\w]\") |&gt; printfn \"%d\" // count 3 letter words\n</code></pre>"},{"location":"2024/12/13/3-regex/#regex-quick-reference-microsoft","title":"regex - Quick Reference (Microsoft)","text":"<p>https://learn.microsoft.com/en-us/dotnet/standard/base-types/regular-expression-language-quick-reference</p>"},{"location":"2024/12/13/3-regex/#cheat-sheet","title":"Cheat sheet","text":"<p>Character escapes <pre><code>\\t     matches a tab \\u0009\n\\r     match a carriage return \\u000D\n\\n     new line \\u000A\n\\unnnn match a unicode character by hexadecimal representation, exactly 4 digits\n\\.     match a dot (not any character) aka. match literally\n\\*     match an asterisk (don't interpret * as a regex special quantifier)\n</code></pre></p> <p>Character classes <pre><code>[character_group]       /[ae]/ will match \"a\" in \"gray\"\n[^not_character_group]\n[a-z] [A-Z] [a-z0-9A-Z] character ranges\n.                       wildcard - any character except \\n except when using SingleLine option\n\\w                      word character - upper/lower case letters and numbers\n\\W                      non word character\n\\s                      white-space character\n\\S                      non whitespace character\n\\d                      digit\n\\D                      non digit\n</code></pre></p> <p>Anchors <pre><code>^   $ beginning and end of a string (in multiline mode beginning and end of a line)\n</code></pre></p> <p>Grouping <pre><code>(subexpression)               (\\w)\\1 - match a character and the same character again - \"aa\" in \"xaax\"\n(?&lt;name&gt;subexpression)        named group (?&lt;double&gt;\\w)\\k&lt;double&gt; - same as above\n(?:subexpression)             noncapturing group - Write(?:Line)? - will match both Write and WriteLine in a string\n                              (:?Mr\\. |Ms\\. |Mrs\\. )?\\w+\\s\\w+ -&gt; match fist name, last name and optional preceding title\n(?imnsx-imnsx: subexpression) turn options on or off for a group\n(?=subexp)                    zero-width positive lookahead assertion\n(?!subexp)                    negative lookahead\n(?&lt;=subexp)\n(?&lt;!subexp)                   look behind assertions\n                              make sure a subexp is/is not following (but don't match it, ie. don't consume the characters)\n</code></pre></p> <p>Quantifiers <pre><code>*     0...n (all these are greedy by default -&gt; match as many as possible)\n+     1...n\n?     0...1\n{n}   exactly n\n{n,}  at least n\n{n,m} n...m\n*?\n+?\n??\n{n,}?\n{n,m}? question mark makes the match nongreedy (mach as few as possible)\n</code></pre></p> <p>Backreference <pre><code>\\number   match the value of a previous subexpression - (\\w)\\1 - matches the same \\w character twice\n\\k&lt;name&gt;  backreference using group name\n</code></pre></p> <p>Alternation Constructs <pre><code>| - any element separated by | - th(e|is|at) and the|this|that both match \"the\" \"this\" \"that\"\n    ala|ma|kota - match \"ala\" or \"ma\" or \"kota\"\n    ala ma (kota|psa) - match \"ala ma kota\" or \"ala ma psa\"\nTODO - match yes if expresion else match no\n</code></pre></p> <p>Substitution <pre><code>$number use numbered group\n${name} use named group\n$$      literal $\n$&amp;      whole match\n$`      text before the match\n$'      text after the match\n$+      last group\n$_      entier input string\n</code></pre></p> <p>Inline options <pre><code>(?imnsx-imnsx)               use it like this at the beginning\n(?imnsx-imnsx:subexpression) use for a group\ni                            case insensetive\nm                            multiline - match beginning and end of a line\nn                            do not capture unnamed groups\ns                            signle line - . matches \\n also\n</code></pre> More options are available using <code>RegexOptions</code> enum</p>"},{"location":"2024/12/13/3-regex/#practice-regex","title":"Practice regex","text":"<p>https://regex101.com/quiz</p> <p>https://regexcrossword.com/</p> <p>https://alf.nu/RegexGolf</p>"},{"location":"2024/12/13/3-regex/#tutorial","title":"Tutorial","text":"<p>I recall reading this tutorial years ago and I liked it - https://www.regular-expressions.info/tutorial.html</p>"},{"location":"2024/12/13/3-regex/#misc","title":"Misc","text":"<p>https://blog.codinghorror.com/regular-expressions-now-you-have-two-problems/</p> <p>I love regex.</p> <p>However I used to say \"if you solve a problem with regex now you have 2 problems\"</p> <p>Not knowing how this quote came to be I repeated it for years. I'll smack the next person to repeat this quote without elaborating.</p> <p>If regex did not exist, it would be necessary to invent it.</p> <p>Why does <code>.Matches()</code> return a custom collection instead of <code>List&lt;Match&gt;</code>?</p> <p>Historic reasons. <code>Regex</code> was made in .Net 1.0 before generic were a thing.</p> <p>https://github.com/dotnet/runtime/discussions/74919?utm_source=chatgpt.com</p> <p>I used <code>(?&lt;!\\[.*?)(?&lt;!\\(\")https?://\\S+</code> with replace <code>[$&amp;]($&amp;)</code> to linkify links in this post</p> <p>My lovely regex helpers <pre><code>let regexExtract  regex                      text = Regex.Match(text, regex).Value\nlet regexExtractg regex                      text = Regex.Match(text, regex).Groups.[1].Value\nlet regexExtracts regex                      text = Regex.Matches(text, regex) |&gt; Seq.map (fun x -&gt; x.Value)\nlet regexReplace  regex (replacement:string) text = Regex.Replace(text, regex, replacement)\nlet regexRemove   regex                      text = Regex.Replace(text, regex, String.Empty)\n</code></pre></p>"},{"location":"2024/12/29/json/","title":"Json","text":"<p>Should I use <code>System.Text.Json</code> (STJ) or <code>Newtonsoft.Json</code> (previously <code>Json.NET</code>)?</p> <p>use STJ, Newtonsoft is no longer enhanced with new features. The author works for Microsoft now on some non-json stuff.</p> <p>JamesNK reddit comment</p>"},{"location":"2024/12/29/json/#terms","title":"Terms","text":"<p>marshal - assemble and arrange (a group of people, especially troops) in order.</p> <p>\"the general marshalled his troops\"</p> <p>marshalling (UK) (in computer science) (marshal US) - getting parameters from here to there</p> <p>serialization - transforming something (data) to a format usable for storage or transmission over the network</p> <p>https://stackoverflow.com/questions/770474/what-is-the-difference-between-serialization-and-marshaling</p> <p>JSON - Java Script Object Notation - data interchange format. https://www.json.org/json-en.html</p>"},{"location":"2024/12/29/json/#why-this-post","title":"Why this post","text":"<p>While analysing some logs I used <code>FSharp.Data</code>'s <code>JsonProvider</code>. Only a few properties were relevant but <code>JsonProvider</code> stores the whole json in memory. With 10GB of logs to analyse I quick run out of memory.</p> <p>Let's do some testing!</p> <pre><code>open System\nopen System.IO\nopen System.Text.Json\n\nfsi.AddPrinter&lt;DateTimeOffset&gt;(fun dt -&gt; dt.ToString(\"O\"))\n\nEnvironment.CurrentDirectory &lt;- __SOURCE_DIRECTORY__ // ensures the script runs from the directory it's located in\n// -------------------------------------------------------------------------\n\n// sample log entry for testing\ntype LogEntry = {\n    Timestamp : DateTimeOffset\n    Level     : string\n    Message   : string\n}\n\n// only the properties we're interested in\ntype LogEntryRecord = {\n    Timestamp : DateTimeOffset\n    Level     : string\n}\n\nlet random = Random()\nlet levels = [ \"INFO\"; \"WARN\"; \"ERROR\"; \"DEBUG\" ]\n\nlet generateLogEntry () =\n    {\n        Timestamp = DateTimeOffset.Now.AddSeconds(-random.Next(0, 10000))\n        Level     = levels.[random.Next(levels.Length)]\n        Message   = String.replicate(random.Next(10, 100)) \"x\" // random string to simulate redundant content\n    }\n\nList.init 7_000_000 (fun _ -&gt; generateLogEntry()) // 7M entries is around 1GB of data\n|&gt; List.map (fun entry -&gt; JsonSerializer.Serialize(entry))\n|&gt; fun lines -&gt; File.WriteAllLines(\"./logs.json\", lines)\n\nlet lines = File.ReadAllLines \"./logs.json\"\n\nlet runWithMemoryCheck lines singleLineParser =\n    GC.Collect()\n    let before = GC.GetTotalMemory(true)\n    let x = lines |&gt; Array.map singleLineParser\n    GC.Collect()\n    let after = GC.GetTotalMemory(true)\n    let m = ((after - before) |&gt; float) / 1024. / 1024. / 1024. // GB\n    x, m\n\n#time\n// -------------------------------------------------------------------------\n\nopen System.Text.Json.Nodes\n\n#r \"nuget: FSharp.Data\"\nopen FSharp.Data\n\n#r \"nuget: FSharp.Json\"\nopen FSharp.Json\n\ntype LogEntryJsonProvider = JsonProvider&lt;\"\"\"\n{\n    \"Timestamp\"        : \"2024-12-23T20:51:18.2020753+01:00\",\n    \"Level\"            : \"ERROR\",\n    \"Message\"          : \"File not found\"\n}\"\"\"&gt;\n\nlet fSharpDataJsonProvider = LogEntryJsonProvider.Parse\n\nlet fSharpDataJsonValue (x:string) =\n    let line = x |&gt; FSharp.Data.JsonValue.Parse\n    let t = line.GetProperty(\"Timestamp\").AsDateTimeOffset()\n    let l = line.GetProperty(\"Level\").AsString()\n    { Timestamp = t; Level = l }\n\nlet stjJsonSerializer (x:string) = JsonSerializer.Deserialize&lt;LogEntryRecord&gt;(x)\n\nlet stjJsonNode (line:string) =\n    let line = line |&gt; JsonNode.Parse\n    let t = line.[\"Timestamp\"].GetValue&lt;DateTimeOffset&gt;()\n    let l = line.[\"Level\"].GetValue&lt;string&gt;()\n    { Timestamp = t; Level = l }\n\nlet stjJsonDocument (x:string) =\n    use doc = x |&gt; JsonDocument.Parse\n    let t = doc.RootElement.GetProperty(\"Timestamp\").GetDateTimeOffset()\n    let l = doc.RootElement.GetProperty(\"Level\").GetString()\n    { Timestamp = t; Level = l }\n\nlet sharpJson (x:string) = Json.deserialize&lt;LogEntryRecord&gt; x\n\nrunWithMemoryCheck lines fSharpDataJsonProvider |&gt; snd |&gt; printfn \"Memory used: %f GB\" // Memory used: 4.420363 GB | Real: 00:00:35.829, CPU: 00:02:07.312, GC gen0: 84,   gen1: 25,  gen2: 8\nrunWithMemoryCheck lines fSharpDataJsonValue    |&gt; snd |&gt; printfn \"Memory used: %f GB\" // Memory used: 0.521624 GB | Real: 00:00:16.557, CPU: 00:00:35.281, GC gen0: 29,   gen1: 10,  gen2: 4\nrunWithMemoryCheck lines stjJsonSerializer      |&gt; snd |&gt; printfn \"Memory used: %f GB\" // Memory used: 0.521555 GB | Real: 00:00:10.823, CPU: 00:00:44.453, GC gen0: 11,   gen1: 6,   gen2: 4\nrunWithMemoryCheck lines stjJsonNode            |&gt; snd |&gt; printfn \"Memory used: %f GB\" // Memory used: 0.521419 GB | Real: 00:00:09.533, CPU: 00:00:27.359, GC gen0: 16,   gen1: 7,   gen2: 4\nrunWithMemoryCheck lines stjJsonDocument        |&gt; snd |&gt; printfn \"Memory used: %f GB\" // Memory used: 0.521525 GB | Real: 00:00:06.208, CPU: 00:00:17.546, GC gen0: 5,    gen1: 4,   gen2: 4\nrunWithMemoryCheck lines sharpJson              |&gt; snd |&gt; printfn \"Memory used: %f GB\" // Memory used: 0.520846 GB | Real: 00:01:02.761, CPU: 00:01:20.578, GC gen0: 1022, gen1: 260, gen2: 4\n</code></pre>"},{"location":"2024/12/29/json/#conclusion","title":"Conclusion","text":"<ul> <li><code>FSharp.Data.JsonProvider</code> is terrible compared to any other alternative (slow and uses lots more memory)</li> <li><code>STJ.JsonDocument</code> is the speed winner.</li> <li><code>FSharp.Json</code> supports F# types but it quite slow</li> </ul>"},{"location":"2024/12/29/json/#systemtextjson-cheat-sheet","title":"<code>System.Text.Json</code> cheat sheet","text":"<ul> <li>JsonSerializer -&gt; deserialize into fixed type</li> <li>JsonDocument   -&gt; immutable (for reading only)</li> <li>JsonDocument   -&gt; faster, IDisposable, uses shared memory pool</li> <li>JsonNode       -&gt; mutable (you can construct json)</li> </ul> <p><code>JsonNode</code> vs <code>JsonDocument</code> see https://learn.microsoft.com/en-us/dotnet/standard/serialization/system-text-json/use-dom#json-dom-choices</p>"},{"location":"2024/12/29/json/#systemtextjsonjsonserializer","title":"<code>System.Text.Json.JsonSerializer</code>","text":"<pre><code>open System\nopen System.Text.Json\n\n// The System.Text.Json namespace contains all the entry points and the main types.\n// The System.Text.Json.Serialization namespace contains attributes and APIs for advanced scenarios and customization specific to serialization and deserialization.\n\n// System.Text.Json.JsonSerializer -&gt; is a static class\n//                                 -&gt; you can instantiate and reuse the JsonSerialization options\n\nlet jsonString = \"\"\"{\n    \"PropertyName1\" : \"dummyValue\",\n    \"PropertyName2\" : 42,\n    \"PropertyName3\" : \"2024-12-29T10:31:36.3774099+01:00\",\n    \"PropertyName4\" : {\"NestedProperty\" : 42},\n    \"PropertyName5\" : [\n        42,\n        11\n    ]\n}\"\"\"\n\ntype InnerType = {\n    NestedProperty: int\n}\n\ntype DummyType = {\n    PropertyName1: string\n    PropertyName2: int\n    PropertyName3: DateTimeOffset\n    PropertyName4: InnerType\n    PropertyName5: int list\n}\n\ntype LogEntryRecord = {\n    Timestamp: DateTimeOffset\n    Level    : string\n}\n\n\n// # JsonSerializer.Deserialize\n\n// JsonSerializer.Deserialize&lt;'Type&gt;(jsonString)\n// JsonSerializer.Deserialize&lt;'Type&gt;(jsonString, options)\n// JsonSerializer.DeserializeAsync(stream, ...) &lt;- only streams can be parsed async cuz parsing string is purely CPU bound\n\n// Deserialization behaviour:\n//  - By default, property name matching is case-sensitive. You can specify case-insensitivity.\n//  - Non-public constructors are ignored by the serializer.\n//  - Deserialization to immutable objects or properties that don't have public set accessors is supported but not enabled by default.\n//    ^ I'm not sure about this cuz F# records seem to work just fine\n\nJsonSerializer.Deserialize&lt;LogEntryRecord&gt;(jsonString)\n// { Timestamp = 0001-01-01T00:00:00.0000000+00:00 Level = null }\n// no properties match but JsonSerializer just returns default values\n\nJsonSerializer.Deserialize&lt;DummyType&gt;(jsonString)\n// val it: DummyType = { PropertyName1 = \"dummyValue\"\n//                       PropertyName2 = 42\n//                       PropertyName3 = 2024-12-29T10:31:36.3774099+01:00\n//                       PropertyName4 = { NestedProperty = 42 }\n//                       PropertyName5 = [42; 11] }\n\n// Deserialization is case sensitive by default!\nlet jsonString2 = \"\"\"{\n    \"propertyName1\" : \"dummyValue\",\n    \"propertyName2\" : 42\n}\"\"\"\nJsonSerializer.Deserialize&lt;DummyType&gt;(jsonString2)\n// val it: DummyType = { PropertyName1 = null\n//                       PropertyName2 = 0\n//                       PropertyName3 = 0001-01-01T00:00:00.0000000+00:00\n//                       PropertyName4 = null\n//                       PropertyName5 = null }\nlet options = new JsonSerializerOptions()\noptions.PropertyNameCaseInsensitive &lt;- true\nJsonSerializer.Deserialize&lt;DummyType&gt;(jsonString2, options)\n// val it: DummyType = { PropertyName1 = \"dummyValue\"\n//                       PropertyName2 = 42\n//                       PropertyName3 = 0001-01-01T00:00:00.0000000+00:00\n//                       PropertyName4 = null\n//                       PropertyName5 = null }\n\n\n// # JsonSerializer.Serialize\n\n// let's pretty print during testing\n// by default the json is minified\nlet options = new JsonSerializerOptions()\noptions.WriteIndented &lt;- true\n\nJsonSerializer.Serialize(options, options)\n//val it: string =\n//  \"{\n//  \"Converters\": [],\n//  \"TypeInfoResolver\": {},\n//  \"TypeInfoResolverChain\": [\n//    {}\n//  ],\n//  \"AllowOutOfOrderMetadataProperties\": false,\n//  \"AllowTrailingCommas\": false,\n//  \"DefaultBufferSize\": 16384,\n//  \"Encoder\": null,\n//  \"DictionaryKeyPolicy\": null,\n//  \"IgnoreNullValues\": false,\n//  \"DefaultIgnoreCondition\": 0,\n//  ...\n\n// Serialization behaviour:\n//  - by default, all public properties are serialized. You can specify properties to ignore. You can also include private members.\n//  - by default, JSON is minified. You can pretty-print the JSON.\n//  - by default, casing of JSON names matches the .NET names. You can customize JSON name casing.\n//  - by default, fields are ignored. You can include fields.\n</code></pre>"},{"location":"2024/12/29/json/#systemtextjsonjsonnode","title":"<code>System.Text.Json.JsonNode</code>","text":"<pre><code>open System\nopen System.Text.Json.Nodes\n\nlet jsonString = \"\"\"{\n    \"PropertyName1\" : \"dummyValue\",\n    \"PropertyName2\" : 42,\n    \"PropertyName3\" : \"2024-12-29T10:31:36.3774099+01:00\",\n    \"PropertyName4\" : {\"NestedProperty\" : 42},\n    \"PropertyName5\" : [\n        42,\n        11\n    ]\n}\"\"\"\n\nlet x = JsonNode.Parse(jsonString) // type(x) = JsonNode\nx.ToJsonString()\nx.[\"PropertyName3\"].GetValue&lt;DateTimeOffset&gt;()\nx.[\"PropertyName3\"].GetPath()\nx.[\"PropertyName4\"].[\"NestedProperty\"].GetPath()\nx.[\"PropertyName2\"] |&gt; int\n// x.[\"PropertyName3\"] |&gt; DateTimeOffset // TODO - why can't I use this explicit conversion?\n\nx[\"PropertyName4\"].GetValueKind() |&gt; string // \"Object\"\nx[\"NonExistingProperty\"] // null\nx[\"NonExistingProperty\"].GetValue&lt;int&gt;() // err - System.NullReferenceException\nx[\"PropertyName5\"].AsArray() |&gt; Seq.map (fun a -&gt; a.GetValue&lt;int&gt;()) // ok\nx[\"PropertyName5\"].AsArray() |&gt; Seq.map int // ok\nx[\"PropertyName5\"].[0].GetValue&lt;int&gt;() // ok\n\n// create a json object\nlet m = new JsonObject()\nm[\"TimeStamp\"] &lt;- DateTimeOffset.Now\nm.ToJsonString() // {\"TimeStamp\":\"2024-12-29T16:06:17.046746+01:00\"}\nm[\"SampleProperty\"] &lt;- new JsonArray(1,2)\nm.Remove(\"TimeStamp\")\n\nlet a = JsonNode.Parse(\"\"\"{\"x\":{\"y\":[1,2,3]}}\"\"\")\na.[\"x\"] // this is a JasonNode\na.[\"x\"].AsObject() // this returns a JsonObject\na.[\"x\"].AsObject() |&gt; Seq.map (fun x -&gt; printfn \"%A\" x) // iterate over properties of the object\na.[\"x\"].ToJsonString() // you can serialize subsection of the json\n// {\"y\":[1,2,3]}\n\nJsonNode.DeepEquals(x, a) // comparison\n</code></pre>"},{"location":"2024/12/29/json/#systemtextjsonjsondocument","title":"<code>System.Text.Json.JsonDocument</code>","text":"<pre><code>open System\nopen System.Text.Json\n\nlet jsonString = \"\"\"{\n    \"PropertyName1\" : \"dummyValue\",\n    \"PropertyName2\" : 42,\n    \"PropertyName3\" : \"2024-12-29T10:31:36.3774099+01:00\",\n    \"PropertyName4\" : {\"NestedProperty\" : 42},\n    \"PropertyName5\" : [\n        42,\n        11\n    ]\n}\"\"\"\n\nuse x = JsonDocument.Parse(jsonString) // remember this is an IDisposable\nx.RootElement.GetProperty(\"PropertyName1\").GetString()\nx.RootElement.GetProperty(\"PropertyName2\").GetInt32()\nx.RootElement.GetProperty(\"PropertyName3\").GetDateTime()\nx.RootElement.GetProperty(\"PropertyName4\").GetProperty(\"NestedProperty\").GetInt32()\nx.RootElement.GetProperty(\"PropertyName5\").EnumerateArray() |&gt; Seq.map (fun x -&gt; x.GetInt32())\n\nfor i in x.RootElement.GetProperty(\"PropertyName5\").EnumerateArray() do\n    printfn \"%A\" i\n\n// you could also write a generic helper\n\ntype JsonElement with\n  member x.Get&lt;'T&gt;(name:string) : 'T =\n    let p = x.GetProperty(name)\n    match typeof&lt;'T&gt; with\n    | t when t = typeof&lt;string&gt; -&gt; p.GetString() |&gt; unbox\n    | t when t = typeof&lt;int&gt; -&gt; p.GetInt32() |&gt; unbox\n    | t when t = typeof&lt;DateTime&gt; -&gt; p.GetDateTime() |&gt; unbox\n    | t when t = typeof&lt;JsonElement&gt; -&gt; p |&gt; unbox\n    | t when t = typeof&lt;int[]&gt; -&gt; p.EnumerateArray() |&gt; Seq.map (fun x -&gt; x.GetInt32()) |&gt; Seq.toArray |&gt; unbox\n    | _ -&gt; failwith \"unsupported type\"\n\nx.RootElement.Get&lt;string&gt;(\"PropertyName1\")\n</code></pre>"},{"location":"2024/12/29/json/#f-types-and-json-serialization","title":"F# types and json serialization","text":"<pre><code>open System.Text.Json\n\n// Record - OK\ntype DummyRecord = {\n    Text: string\n    Num:  int\n    }\n\nlet r = { Text = \"asdf\"; Num = 1 }\n\nJsonSerializer.Serialize(r) |&gt; JsonSerializer.Deserialize&lt;DummyRecord&gt;\n\nlet tuple = (42, \"asdf\")\nJsonSerializer.Serialize(tuple) |&gt; JsonSerializer.Deserialize&lt;int * string&gt;\n\ntype TupleAlias = int * string\nlet tuple2 = (43, \"sfdg\") : TupleAlias\nJsonSerializer.Serialize(tuple2) |&gt; JsonSerializer.Deserialize&lt;TupleAlias&gt;\n\n// Discriminated Union :(\ntype SampleDiscriminatedUnion =\n    | A of int\n    | B of string\n    | C of int * string\nlet x = A 1\nJsonSerializer.Serialize(x) // eeeeeeeeeeeeee !\n\n// Option - OK\nJsonSerializer.Serialize(Some 42) |&gt; JsonSerializer.Deserialize&lt;int option&gt;\nJsonSerializer.Serialize(None) |&gt; JsonSerializer.Deserialize&lt;int option&gt;\nopen System\ntype RecordTest2 = {\n    Timestamp: DateTimeOffset\n    Level: string\n    TestOp: int option\n    }\n\n// Discriminated Union is supported in FSharp.Json\n// https://github.com/fsprojects/FSharp.Json\n#r \"nuget: FSharp.Json\"\nopen FSharp.Json\nlet data = C (42, \"The string\")\nlet json = Json.serialize data\n// val json: string = \"{\n//   \"C\": [\n//     42,\n//     \"The string\"\n//   ]\n// }\n\nlet deserialized = Json.deserialize&lt;SampleDiscriminatedUnion&gt; json\n// val deserialized: SampleDiscriminatedUnion = C (42, \"The string\")\n</code></pre>"},{"location":"2024/12/29/json/#more-on-fsharpdatas-jsonvalue","title":"More on <code>FSharp.Data</code>'s <code>JsonValue</code>","text":"<pre><code>#r \"nuget:FSharp.Data\"\nopen FSharp.Data\n\nlet j = JsonValue.Parse(\"\"\"{\"x\":{\"y\":[1,2,3]}}\"\"\")\nj.Properties()\n// val it: (string * JsonValue) array =\n//   [|(\"x\", {\n//   \"y\": [\n//     1,\n//     2,\n//     3\n//   ]\n// })|]\nj.[\"x\"].[\"y\"].AsArray()\nj.TryGetProperty \"x\"\n\n// JsonValue is a discriminated union\n// union JsonValue =\n//   | String  of string\n//   | Number  of decimal\n//   | Float   of float\n//   | Record  of properties: (string * JsonValue) array\n//   | Array   of elements: JsonValue array\n//   | Boolean of bool\n//   | Null\n//\n// docs:\n// https://fsprojects.github.io/FSharp.Data/reference/fsharp-data-jsonvalue.html\n// https://fsprojects.github.io/FSharp.Data/library/JsonValue.html &lt;- if you'll be working with JsonValue read this\n//\n// there are also extension methods:\n// https://fsprojects.github.io/FSharp.Data/reference/fsharp-data-jsonextensions.html\n//\n// AsArray doesn't fail if the value is not an array, as opposed to other AsSth methods\n// See below how extension methods are defined\n// source: https://github.com/fsprojects/FSharp.Data/blob/main/src/FSharp.Data.Json.Core/JsonExtensions.fs\nopen System.Globalization\nopen System.Runtime.CompilerServices\nopen System.Runtime.InteropServices\nopen FSharp.Data.Runtime\nopen FSharp.Core\n\n[&lt;Extension&gt;]\ntype JsonExtensions =\n    /// Get all the elements of a JSON value.\n    /// Returns an empty array if the value is not a JSON array.\n    [&lt;Extension&gt;]\n    static member AsArray(x: JsonValue) =\n        match x with\n        | (JsonValue.Array elements) -&gt; elements\n        | _ -&gt; [||]\n\n    /// Get a number as an integer (assuming that the value fits in integer)\n    [&lt;Extension&gt;]\n    static member AsInteger(x, [&lt;Optional&gt;] ?cultureInfo) =\n        let cultureInfo = defaultArg cultureInfo CultureInfo.InvariantCulture\n\n        match JsonConversions.AsInteger cultureInfo x with\n        | Some i -&gt; i\n        | _ -&gt;\n            failwithf \"Not an int: %s\"\n            &lt;| x.ToString(JsonSaveOptions.DisableFormatting)\n\n// construct a json object\nlet d =\n    JsonValue.Record [|\n        \"event\",      JsonValue.String \"asdf\"\n        \"properties\", JsonValue.Record [|\n            \"token\",       JsonValue.String \"tokenId\"\n            \"distinct_id\", JsonValue.String \"123123\"\n        |]\n    |]\n\nd.ToString().Replace(\"\\r\\n\", \"\").Replace(\" \", \"\")\n\n// if you want to process the json object\nfor (k, v) in d.Properties() do\n    printfn \"Property: %s\" k\n    match v with\n    | JsonValue.Record props -&gt; printfn \"\\t%A\" props\n    | JsonValue.String s     -&gt; printfn \"\\t%A\" s\n    | JsonValue.Number n     -&gt; printfn \"\\t%A\" n\n    | JsonValue.Float f      -&gt; printfn \"\\t%A\" f\n    | JsonValue.Array a      -&gt; printfn \"\\t%A\" a\n    | JsonValue.Boolean b    -&gt; printfn \"\\t%A\" b\n    | JsonValue.Null         -&gt; printfn \"\\tnull\"\n</code></pre>"},{"location":"2024/12/29/json/#serialize-straight-to-utf-8","title":"Serialize straight to UTF-8","text":"<p><code>JsonSerializer.SerializeToUtf8Bytes(value, options)</code> &lt;- why does this one exist?</p> <p>Strings in .Net are stored in memory as UTF-16, so if you don't need a string, you can use this method and serialize straight to UTF-8 bytes (it's 5-10% faster, see link) https://learn.microsoft.com/en-us/dotnet/standard/serialization/system-text-json/how-to#serialize-to-utf-8</p>"},{"location":"2024/12/29/json/#more-links","title":"More links","text":"<p>https://stu.dev/a-look-at-jsondocument/</p> <p>https://blog.ploeh.dk/2023/12/18/serializing-restaurant-tables-in-f/</p> <p>https://devblogs.microsoft.com/dotnet/try-the-new-system-text-json-apis/?ref=stu.dev - a post from when they introduced the new json API</p> <p>TODO for myself - watch these maybe</p> <ul> <li>https://www.youtube.com/watch?v=TjVcVWB0oFk&amp;list=PLEzQf147-uEoNCeDlRrXv6ClsLDN-HtNm&amp;index=1</li> <li>https://www.infoq.com/presentations/Heretical-Open-Source/</li> </ul>"},{"location":"2025/01/20/environment-variable/","title":"Environment variable","text":""},{"location":"2025/01/20/environment-variable/#but-only-in-a-specific-directory","title":"but only in a specific directory","text":"<p>The idea - use the <code>Prompt</code> function to check if you're in a specific dir and set/unset an env var:</p> <pre><code>function Prompt {\n    $currentDir = Get-Location\n    if (\"C:\\git\\that-special-dir\" -eq $currentDir) {\n        $env:THAT_SPECIAL_ENV_VAR = \"./extra.cer\"\n    }\n    else {\n        Remove-Item Env:\\THAT_SPECIAL_ENV_VAR\n    }\n}\n</code></pre> <p>Extract the special env setting/unsetting to a function:</p> <pre><code>function SetOrUnSet-DirectoryDependent-EnvironmentVariables {\n    $currentDir = Get-Location\n    if (\"C:\\git\\that-special-dir\" -eq $currentDir) {\n        $env:THAT_SPECIAL_ENV_VAR = \"./extra.cer\"\n    }\n    else {\n        Remove-Item Env:\\THAT_SPECIAL_ENV_VAR\n    }\n}\n\nfunction Prompt {\n    SetOrUnSet-DirectoryDependent-EnvironmentVariables\n}\n</code></pre> <p>If your <code>Prompt</code> function is already overwritten by ex. <code>oh-my-posh</code>:</p> <pre><code>function SetOrUnSet-DirectoryDependent-EnvironmentVariables {\n    $currentDir = Get-Location\n    if (\"C:\\git\\that-special-dir\" -eq $currentDir) {\n        $env:THAT_SPECIAL_ENV_VAR = \"./extra.cer\"\n    }\n    else {\n        Remove-Item Env:\\THAT_SPECIAL_ENV_VAR\n    }\n}\n\n$promptFunction = (Get-Command Prompt).ScriptBlock\n\nfunction Prompt {\n    SetOrUnSet-DirectoryDependent-EnvironmentVariables\n    $promptFunction.Invoke()\n}\n</code></pre>"},{"location":"2025/01/20/environment-variable/#why-did-i-need-this","title":"Why did I need this?","text":"<p>In a repository with several js scrapers run by <code>NODE</code> a few scrape data from misconfigured websites. These websites don't provide the intermediate certificate for https. Your browser automatically fills in the gap for convenience but a simple http client like <code>axios</code> will rightfully reject the connection as it can't verify who it is talking to (see more here)</p> <p>Solution?</p> <p>Use NODE_EXTRA_CA_CERTS</p> <ul> <li>You configure your production server with <code>NODE_EXTRA_CA_CERTS</code>.</li> <li>When testing locally you get tired of remembering to set <code>NODE_EXTRA_CA_CERTS</code>.</li> <li>You add <code>NODE_EXTRA_CA_CERTS</code> to your powershell profile. Now every time you run anything using <code>NODE</code> (like vs code) you see <pre><code>Warning: Ignoring extra certs from `./extra.cer`, load failed: error:02000002:system library:OPENSSL_internal:No such file or directory\n</code></pre></li> <li>You get annoyed and you ask yourself how to set an environment variable but only in a specific directory</li> </ul> <p>I use this myself here -&gt; the public part of my powershell-profile</p>"},{"location":"2025/01/23/post21/","title":"Post21","text":"<pre><code>blood stains in the snow\nyou left a few\njumping home\nfor me to remember the last walk\nsnow will melt soon\nthis memory\nI will not let fade\nyou were loved\nand you loved us too\nof that I'm sure\nit's a tough call\nto let you sleep\ndon't fear wherever you go\nremember wide beaches\nyou used to love\nwe will be there someday to\n</code></pre> <pre><code>Plamy krwi na \u015bniegu\nzostawi\u0142a\u015b kilka,\nwracaj\u0105c do domu,\nabym zapami\u0119ta\u0142 ostatni spacer.\n\u015anieg wkr\u00f3tce stopnieje,\nale to wspomnienie\nnie pozwol\u0119 mu odej\u015b\u0107.\nBy\u0142a\u015b kochana\ni kocha\u0142e\u015b te\u017c nas,\ntego jestem pewien.\nTo trudna decyzja,\npozwoli\u0107 ci zasn\u0105\u0107.\nNie b\u00f3j si\u0119, dok\u0105dkolwiek zmierzasz,\npami\u0119taj o szerokich pla\u017cach,\nkt\u00f3re tak kocha\u0142a\u015b.\nCzekaj tam na nas,\nW ko\u0144cu przyjdziemy.\n</code></pre>"},{"location":"2025/01/28/post22/","title":"Post22","text":"<pre><code>W chatce w lesie siedzi Pan\nNie odzywa si\u0119 do nikogo bo jest sam\nMy\u015bli ci\u0119\u017ckie, g\u0142owa pogr\u0105\u017cona w chorobie\nZaraz zawi\u015bnie na grobie\nWspomnienia zapl\u0105tane same w sobie\nSiedzi, mruga, w\u0142asn\u0105 g\u0142ow\u0119 zruga\nPora zaraz b\u0119dzie na spanie\nA on wci\u0105\u017c, o matko Boska, gdzie jego pos\u0142anie?\nPoradzi\u0107 nic nie mo\u017ce, bo siedzi wci\u0105\u017c na dworze\nRobaczki, wyka\u0142aczki go wkurwiaj\u0105\nChcia\u0142by uciec jak ten zaj\u0105c\nco poradzi\u0107 temu Panu?\nMy\u015bl\u0119 \u017ce to cud \u017ce doszed\u0142 a\u017c tu\nDrogi mia\u0142 w brud\nCo zrobi\u0107? Ktr pomo\u017ce\nMatko boska on wci\u0105\u017c siedzi na dworze\nSiedzi, mruga\nFajk\u0119 pyka\nTyto\u0144 s\u0142aby\nJest ju\u017c ca\u0142y osiwia\u0142y\n</code></pre>"},{"location":"2025/02/08/powershell-gotcha---dynamic-scoping/","title":"PowerShell Gotcha! - dynamic scoping","text":"<p>PowerShell uses dynamic scoping. Yet the about_Scopes page doesn't mention the word \"dynamic\".</p> <p>Wird (wird - so weird that you need to misspell weird to get your point across).</p>"},{"location":"2025/02/08/powershell-gotcha---dynamic-scoping/#tldr","title":"tl;dr;","text":"<p>In PowerShell variables are copied into the stack frame created for the function you're calling. So the \"child\" function can use your variables but can only modify its own copies. You can avoid this by setting your variable to private <code>$private:varName=...</code> and using <code>Set-StrictMode -version latest</code> to throw an error if \"child\" functions try to access a undefined variable.</p> <p>PowerShell uses dynamic scoping. What we know from most programming languages is lexical scoping.</p> <p><pre><code>function Do-InnerFunction  { Write-Host $t }\nfunction Do-OutterFunction {\n    $t = \"hello\"\n    Do-InnerFunction\n}\n\nDo-OutterFunction\n</code></pre> <pre><code>hello\n</code></pre></p> <p>Weird! (this is dynamic scoping)</p> <pre><code>Set-StrictMode -Version Latest\nfunction Do-InnerFunction  { Write-Host $t }\nfunction Do-OutterFunction {\n    $t = \"hello\"\n    Do-InnerFunction\n}\n\nDo-OutterFunction\nSet-StrictMode -Off # remember to turn strict mode off for further testing\n</code></pre> <pre><code>hello\n</code></pre> <p>Weird! (but makes sense since in PowerShell's world this is perfectly legal hence \"strict\" changes nothing here)</p> <pre><code>function Do-InnerFunction  { Write-Host $t }\nfunction Do-OutterFunction {\n    $private:t = \"hello\"\n    Do-InnerFunction\n}\n\nDo-OutterFunction\n</code></pre> <pre><code>\n</code></pre> <p>Output is empty. No errors but at least <code>$t</code> behaves more like a variable we know from C#/F#.</p> <pre><code>Set-StrictMode -Version Latest\nfunction Do-InnerFunction  { Write-Host $t }\nfunction Do-OutterFunction {\n    $private:t = \"hello\"\n    Do-InnerFunction\n}\n\nDo-OutterFunction\n</code></pre> <pre><code>InvalidOperation: C:\\Users\\...\\Temp\\44f5ff41-4105-482b-a134-b505049d2c61\\test3.ps1:2\nLine |\n   2 |      Write-Host $t\n     |                 ~~\n     | The variable '$t' cannot be retrieved because it has not been set.\n</code></pre> <p>Finally!</p> <pre><code>function Do-InnerFunction {\n    Write-Host $t\n    $t = \"world\"\n    Write-Host $t\n}\n\nfunction Do-OutterFunction {\n    $t = \"hello\"\n    Do-InnerFunction\n    Write-Host $t\n}\n\nDo-OutterFunction\n</code></pre> <pre><code>hello\nworld\nhello\n</code></pre> <p>Ah! So variables are copied to the next \"scope\".</p> <pre><code>function Do-InnerFunction {\n    Write-Host $t\n    $global:t = \"world\"\n    Write-Host $t\n}\n\nfunction Do-OutterFunction {\n    $t = \"hello\"\n    Do-InnerFunction\n    Write-Host $t\n}\n\nDo-OutterFunction\nWrite-Host $t\n</code></pre> <pre><code>hello\nhello\nhello\nworld\n</code></pre> <p>Now we have created a <code>global</code> <code>$t</code> variable.</p> <p>This https://ig2600.blogspot.com/2010/01/powershell-is-dynamically-scoped-and.html explains it nicely.</p>"},{"location":"archive/2025/","title":"2025","text":""},{"location":"archive/2024/","title":"2024","text":""},{"location":"archive/2023/","title":"2023","text":""},{"location":"archive/2022/","title":"2022","text":""},{"location":"archive/2021/","title":"2021","text":""},{"location":"category/powershell/","title":"PowerShell","text":""},{"location":"category/poem/","title":"poem","text":""},{"location":"category/f-sharp/","title":"F Sharp","text":""},{"location":"category/json/","title":"json","text":""},{"location":"category/regex/","title":"regex","text":""},{"location":"category/scripting/","title":"scripting","text":""},{"location":"category/exercises/","title":"exercises","text":""},{"location":"category/general-coding/","title":"General coding","text":""},{"location":"category/experience/","title":"experience","text":""},{"location":"category/tools/","title":"Tools","text":""},{"location":"category/team-lead/","title":"Team lead","text":""},{"location":"category/certificates/","title":"certificates","text":""},{"location":"category/keys/","title":"keys","text":""},{"location":"category/ssl/","title":"SSL","text":""},{"location":"category/https/","title":"HTTPS","text":""},{"location":"category/node/","title":"node","text":""},{"location":"category/npm/","title":"npm","text":""},{"location":"category/js/","title":"js","text":""},{"location":"category/dependencies/","title":"dependencies","text":""},{"location":"category/axios/","title":"axios","text":""},{"location":"category/cookies/","title":"cookies","text":""},{"location":"category/bash/","title":"bash","text":""},{"location":"page/2/","title":"Blog","text":""}]}